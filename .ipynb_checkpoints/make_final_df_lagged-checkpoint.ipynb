{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8cb0197-2adf-4a96-bfd4-3303530f0ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_2878948/3434667788.py:155: DtypeWarning: Columns (47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  input_data = pd.read_csv(IN_CSV)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /explore/nobackup/people/spotter5/anna_v/v2/v2_model_training_v4_lagged.csv\n",
      "                 site_reference  year  month  tmmn  tmmx  tmean_C    pr  \\\n",
      "0   ARM-NSA-Barrow_US-A10_tower  2001      7   0.8   7.6     4.20  36.0   \n",
      "1   ARM-NSA-Barrow_US-A10_tower  2001      8   0.1   5.3     2.70  33.0   \n",
      "2   ARM-NSA-Barrow_US-A10_tower  2002      7   1.0   8.3     4.65   2.0   \n",
      "3   ARM-NSA-Barrow_US-A10_tower  2002      8   0.4   5.9     3.15  23.0   \n",
      "4   ARM-NSA-Barrow_US-A10_tower  2002      9   0.3   4.7     2.50  51.0   \n",
      "5   ARM-NSA-Barrow_US-A10_tower  2003      7   1.6   8.7     5.15  24.0   \n",
      "6   ARM-NSA-Barrow_US-A10_tower  2003      8   0.7   5.3     3.00  23.0   \n",
      "7   ARM-NSA-Barrow_US-A10_tower  2003      9  -1.2   2.0     0.40  35.0   \n",
      "8   ARM-NSA-Barrow_US-A10_tower  2004      7   2.9  10.4     6.65  38.0   \n",
      "9   ARM-NSA-Barrow_US-A10_tower  2004      8   4.4  10.1     7.25  22.0   \n",
      "10  ARM-NSA-Barrow_US-A10_tower  2004      9  -1.2   2.6     0.70  34.0   \n",
      "11  ARM-NSA-Barrow_US-A10_tower  2005      7   1.6   7.6     4.60  18.0   \n",
      "\n",
      "       NDVI   temp_ctx     pr_ctx  ndvi_ctx  snow_cover  snow_cover_ctx  \\\n",
      "0   0.27390 -21.587500   2.500000  0.273900    0.590437       98.447266   \n",
      "1   0.34500 -21.587500   2.500000  0.345000    1.989337       98.447266   \n",
      "2   0.54780 -23.030000   2.600000  0.547800    1.012882       98.447266   \n",
      "3   0.54260 -23.030000   2.600000  0.542600    3.026446       98.447266   \n",
      "4   0.44260   3.150000  13.000000  0.545200    5.878448       98.447266   \n",
      "5   0.39735 -21.380000   2.000000  0.397350    0.133902       98.447266   \n",
      "6   0.33410 -21.380000   2.000000  0.334100    2.076954       98.447266   \n",
      "7   0.33410   3.516667  16.666667  0.365725   20.770985       98.447266   \n",
      "8   0.30090 -23.920000   2.600000  0.300900    0.197906       98.447266   \n",
      "9   0.60690 -23.920000   2.600000  0.606900    0.025191       98.447266   \n",
      "10  0.59520   6.100000  27.333333  0.453900   24.242128       98.447266   \n",
      "11  0.59455 -22.220000   3.400000  0.594550    0.217582       98.447266   \n",
      "\n",
      "      snow_depth  snow_depth_ctx  NDSI_snow_cover  ndsi_snow_cover_ctx  \n",
      "0   5.237210e-04        0.510701          -9999.0              -9999.0  \n",
      "1   1.971501e-03        0.510701          -9999.0              -9999.0  \n",
      "2   1.026441e-03        0.339531          -9999.0              -9999.0  \n",
      "3   3.076697e-03        0.339531          -9999.0              -9999.0  \n",
      "4   5.916341e-03        0.339531          -9999.0              -9999.0  \n",
      "5   1.194451e-04        0.440187          -9999.0              -9999.0  \n",
      "6   2.085696e-03        0.440187          -9999.0              -9999.0  \n",
      "7   2.115885e-02        0.440187          -9999.0              -9999.0  \n",
      "8   1.706359e-04        0.519635          -9999.0              -9999.0  \n",
      "9  -7.345365e-24        0.519635          -9999.0              -9999.0  \n",
      "10  3.131646e-02        0.519635          -9999.0              -9999.0  \n",
      "11  1.929498e-04        0.513267          -9999.0              -9999.0  \n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --------- Paths ---------\n",
    "IN_CSV  = \"/explore/nobackup/people/spotter5/anna_v/v2/v2_model_training_data_v4.csv\"\n",
    "SOIL    = \"/explore/nobackup/people/spotter5/anna_v/v2/integrated_soil_data_1km_v2_sites.csv\"\n",
    "LC      = \"/explore/nobackup/people/spotter5/anna_v/v2/extracted_landcover_values_v2.csv\"\n",
    "SM      = \"/explore/nobackup/people/spotter5/anna_v/v2/soil_moisture_by_site_monthly_2000_2023.csv\"\n",
    "CO2     = \"/explore/nobackup/people/spotter5/anna_v/v2/co2_cont.csv\"\n",
    "ALT     = \"/explore/nobackup/people/spotter5/anna_v/v2/ALT_by_site.csv\"\n",
    "\n",
    "OUT_CSV = \"/explore/nobackup/people/spotter5/anna_v/v2/v2_model_training_v4_lagged.csv\"\n",
    "\n",
    "# --------- Helper: context builder for ONE site ---------\n",
    "def build_ctx_for_site(df_site: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply seasonal/context logic to ONE site's data and return df with 6 *_ctx columns added.\n",
    "    Rules:\n",
    "      - Summer obs (JJA): temp/pr = mean(Dec(prev)–Apr(curr)), snow = mean(Dec(prev)–Mar(curr)), ndvi = current NDVI\n",
    "      - Fall (SON):       temp/pr/ndvi = same-year JJA means; snow = mean(Dec(prev)–Mar(curr))\n",
    "      - Winter (DJFM):    temp/pr/ndvi = previous-year JJA means; snow = current month (original)\n",
    "      - Spring (AM):      temp/pr/ndvi = previous-year JJA means; snow = current month (original)\n",
    "      - Fill remaining NaNs using original values, then same-month means (within site), then site means.\n",
    "    \"\"\"\n",
    "    need = ['year','month','tmmn','tmmx','pr','NDVI','snow_cover','snow_depth','NDSI_snow_cover']\n",
    "    miss = [c for c in need if c not in df_site.columns]\n",
    "    if miss:\n",
    "        raise ValueError(f\"Missing columns for context logic: {miss}\")\n",
    "\n",
    "    df = df_site.copy()\n",
    "    df['tmean_C'] = df[['tmmn','tmmx']].mean(axis=1)\n",
    "    df['year']  = pd.to_numeric(df['year'], errors='coerce').astype(int)\n",
    "    df['month'] = pd.to_numeric(df['month'], errors='coerce').astype(int)\n",
    "\n",
    "    # Monthly means (within site) for building aggregates\n",
    "    monthly = (\n",
    "        df.groupby(['year','month'], as_index=False)\n",
    "          .agg({'tmean_C':'mean','pr':'mean','NDVI':'mean',\n",
    "                'snow_cover':'mean','snow_depth':'mean','NDSI_snow_cover':'mean'})\n",
    "          .sort_values(['year','month'])\n",
    "    )\n",
    "\n",
    "    # JJA per year (same-year)\n",
    "    summer = (\n",
    "        monthly[monthly['month'].isin([6,7,8])]\n",
    "        .groupby('year', as_index=False)\n",
    "        .agg({'tmean_C':'mean','pr':'mean','NDVI':'mean'})\n",
    "        .rename(columns={'tmean_C':'summer_tmean','pr':'summer_pr','NDVI':'summer_ndvi'})\n",
    "    )\n",
    "\n",
    "    # Dec(prev)–Apr(curr) mapped to curr year (for JJA temp/pr)\n",
    "    win_DecApr = monthly[monthly['month'].isin([12,1,2,3,4])].copy()\n",
    "    win_DecApr['target_year'] = win_DecApr['year'] + (win_DecApr['month'] == 12).astype(int)\n",
    "    win_DecApr = (\n",
    "        win_DecApr.groupby('target_year', as_index=False)\n",
    "                  .agg({'tmean_C':'mean','pr':'mean'})\n",
    "                  .rename(columns={'target_year':'year',\n",
    "                                   'tmean_C':'Decprev_to_Apr_tmean',\n",
    "                                   'pr':'Decprev_to_Apr_pr'})\n",
    "    )\n",
    "\n",
    "    # Dec(prev)–Mar(curr) mapped to curr year (for JJA & Fall snow)\n",
    "    win_DecMar = monthly[monthly['month'].isin([12,1,2,3])].copy()\n",
    "    win_DecMar['target_year'] = win_DecMar['year'] + (win_DecMar['month'] == 12).astype(int)\n",
    "    win_DecMar = (\n",
    "        win_DecMar.groupby('target_year', as_index=False)\n",
    "                  .agg({'snow_cover':'mean','snow_depth':'mean','NDSI_snow_cover':'mean'})\n",
    "                  .rename(columns={'target_year':'year',\n",
    "                                   'snow_cover':'Decprev_to_Mar_snow_cover',\n",
    "                                   'snow_depth':'Decprev_to_Mar_snow_depth',\n",
    "                                   'NDSI_snow_cover':'Decprev_to_Mar_NDSI'})\n",
    "    )\n",
    "\n",
    "    out = df.copy()\n",
    "    for c in ['temp_ctx','pr_ctx','ndvi_ctx',\n",
    "              'snow_cover_ctx','snow_depth_ctx','ndsi_snow_cover_ctx']:\n",
    "        out[c] = pd.NA\n",
    "\n",
    "    is_summer  = out['month'].isin([6,7,8])      # JJA\n",
    "    is_fall    = out['month'].isin([9,10,11])    # SON\n",
    "    is_winter  = out['month'].isin([12,1,2,3])   # DJFM\n",
    "    is_spring  = out['month'].isin([4,5])        # AM\n",
    "\n",
    "    # A) Summer rows\n",
    "    tmp = out.loc[is_summer, ['year','month']].merge(win_DecApr, on='year', how='left')\n",
    "    out.loc[is_summer, 'temp_ctx'] = tmp['Decprev_to_Apr_tmean'].values\n",
    "    out.loc[is_summer, 'pr_ctx']   = tmp['Decprev_to_Apr_pr'].values\n",
    "    tmp = out.loc[is_summer, ['year','month']].merge(win_DecMar, on='year', how='left')\n",
    "    out.loc[is_summer, 'snow_cover_ctx']      = tmp['Decprev_to_Mar_snow_cover'].values\n",
    "    out.loc[is_summer, 'snow_depth_ctx']      = tmp['Decprev_to_Mar_snow_depth'].values\n",
    "    out.loc[is_summer, 'ndsi_snow_cover_ctx'] = tmp['Decprev_to_Mar_NSI'].values if 'Decprev_to_Mar_NSI' in tmp.columns else tmp['Decprev_to_Mar_NDSI'].values\n",
    "    out.loc[is_summer, 'ndvi_ctx'] = out.loc[is_summer, 'NDVI'].values\n",
    "\n",
    "    # B) Fall rows (same-year JJA for temp/pr/ndvi; Decprev–Mar for snow)\n",
    "    tmp = out.loc[is_fall, ['year','month']].merge(summer, on='year', how='left')\n",
    "    out.loc[is_fall, 'temp_ctx'] = tmp['summer_tmean'].values\n",
    "    out.loc[is_fall, 'pr_ctx']   = tmp['summer_pr'].values\n",
    "    out.loc[is_fall, 'ndvi_ctx'] = tmp['summer_ndvi'].values\n",
    "    tmp = out.loc[is_fall, ['year','month']].merge(win_DecMar, on='year', how='left')\n",
    "    out.loc[is_fall, 'snow_cover_ctx']      = tmp['Decprev_to_Mar_snow_cover'].values\n",
    "    out.loc[is_fall, 'snow_depth_ctx']      = tmp['Decprev_to_Mar_snow_depth'].values\n",
    "    out.loc[is_fall, 'ndsi_snow_cover_ctx'] = tmp['Decprev_to_Mar_NDSI'].values\n",
    "\n",
    "    # C) Winter rows (prev-year JJA for temp/pr/ndvi; snow = original)\n",
    "    prev = out.loc[is_winter, ['year','month']].copy()\n",
    "    prev = prev.merge(summer.rename(columns={'year':'key_year'}),\n",
    "                      left_on=(prev['year'] - 1), right_on='key_year', how='left')\n",
    "    out.loc[is_winter, 'temp_ctx'] = prev['summer_tmean'].values\n",
    "    out.loc[is_winter, 'pr_ctx']   = prev['summer_pr'].values\n",
    "    out.loc[is_winter, 'ndvi_ctx'] = prev['summer_ndvi'].values\n",
    "    out.loc[is_winter, 'snow_cover_ctx']      = out.loc[is_winter, 'snow_cover'].values\n",
    "    out.loc[is_winter, 'snow_depth_ctx']      = out.loc[is_winter, 'snow_depth'].values\n",
    "    out.loc[is_winter, 'ndsi_snow_cover_ctx'] = out.loc[is_winter, 'NDSI_snow_cover'].values\n",
    "\n",
    "    # D) Spring rows (prev-year JJA for temp/pr/ndvi; snow = original)\n",
    "    prev = out.loc[is_spring, ['year','month']].copy()\n",
    "    prev = prev.merge(summer.rename(columns={'year':'key_year'}),\n",
    "                      left_on=(prev['year'] - 1), right_on='key_year', how='left')\n",
    "    out.loc[is_spring, 'temp_ctx'] = prev['summer_tmean'].values\n",
    "    out.loc[is_spring, 'pr_ctx']   = prev['summer_pr'].values\n",
    "    out.loc[is_spring, 'ndvi_ctx'] = prev['summer_ndvi'].values\n",
    "    out.loc[is_spring, 'snow_cover_ctx']      = out.loc[is_spring, 'snow_cover'].values\n",
    "    out.loc[is_spring, 'snow_depth_ctx']      = out.loc[is_spring, 'snow_depth'].values\n",
    "    out.loc[is_spring, 'ndsi_snow_cover_ctx'] = out.loc[is_spring, 'NDSI_snow_cover'].values\n",
    "\n",
    "    # No-NaN fallbacks (within site)\n",
    "    out['temp_ctx'] = out['temp_ctx'].fillna(out['tmean_C'])\n",
    "    out['pr_ctx']   = out['pr_ctx'].fillna(out['pr'])\n",
    "    out['ndvi_ctx'] = out['ndvi_ctx'].fillna(out['NDVI'])\n",
    "    out['snow_cover_ctx']      = out['snow_cover_ctx'].fillna(out['snow_cover'])\n",
    "    out['snow_depth_ctx']      = out['snow_depth_ctx'].fillna(out['snow_depth'])\n",
    "    out['ndsi_snow_cover_ctx'] = out['ndsi_snow_cover_ctx'].fillna(out['NDSI_snow_cover'])\n",
    "\n",
    "    # same-month means within site\n",
    "    month_means = (\n",
    "        out.groupby('month')[['temp_ctx','pr_ctx','ndvi_ctx',\n",
    "                              'snow_cover_ctx','snow_depth_ctx','ndsi_snow_cover_ctx']]\n",
    "          .transform('mean')\n",
    "    )\n",
    "    for col in ['temp_ctx','pr_ctx','ndvi_ctx',\n",
    "                'snow_cover_ctx','snow_depth_ctx','ndsi_snow_cover_ctx']:\n",
    "        out[col] = out[col].fillna(month_means[col])\n",
    "\n",
    "    # site overall means last\n",
    "    for col in ['temp_ctx','pr_ctx','ndvi_ctx',\n",
    "                'snow_cover_ctx','snow_depth_ctx','ndsi_snow_cover_ctx']:\n",
    "        out[col] = out[col].fillna(out[col].mean())\n",
    "\n",
    "    return out\n",
    "\n",
    "# --------- 1) Build context (all sites) ---------\n",
    "input_data = pd.read_csv(IN_CSV)\n",
    "\n",
    "# Keep EC only, valid site_reference, and years >= 2001 (as in your merge script)\n",
    "input_data = input_data[(input_data['flux_method'] == 'EC') &\n",
    "                        (input_data['year'] >= 2001)].copy()\n",
    "input_data = input_data.dropna(subset=['site_reference'])\n",
    "\n",
    "# Apply per-site context logic, then recombine\n",
    "parts = []\n",
    "for site, g in input_data.groupby('site_reference', group_keys=False):\n",
    "    parts.append(build_ctx_for_site(g))\n",
    "ctx_all = pd.concat(parts, ignore_index=True)\n",
    "\n",
    "# --------- 2) Merge additional datasets ---------\n",
    "soil       = pd.read_csv(SOIL)\n",
    "landcover  = pd.read_csv(LC)[['site_refer','land_cover_code']]\n",
    "sm         = pd.read_csv(SM)\n",
    "cont       = pd.read_csv(CO2)\n",
    "alt        = pd.read_csv(ALT)\n",
    "\n",
    "# Normalize types\n",
    "for df in [ctx_all, alt, sm]:\n",
    "    if 'site_reference' in df.columns:\n",
    "        df['site_reference'] = df['site_reference'].astype(str)\n",
    "for df in [soil, landcover]:\n",
    "    if 'site_refer' in df.columns:\n",
    "        df['site_refer'] = df['site_refer'].astype(str)\n",
    "\n",
    "for df in [ctx_all, alt, sm, cont]:\n",
    "    if 'year' in df.columns:\n",
    "        df['year'] = pd.to_numeric(df['year'], errors='coerce').astype('Int64')\n",
    "    if 'month' in df.columns:\n",
    "        df['month'] = pd.to_numeric(df['month'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Deduplicate on merge keys\n",
    "ctx_all   = ctx_all.drop_duplicates(subset=['site_reference','year','month'])\n",
    "soil      = soil.drop_duplicates(subset=['site_refer'])\n",
    "landcover = landcover.drop_duplicates(subset=['site_refer'])\n",
    "alt       = alt.drop_duplicates(subset=['site_reference','year'])\n",
    "sm        = sm.drop_duplicates(subset=['site_reference','year','month'])\n",
    "\n",
    "# Soil (static); keep only 100cm cols\n",
    "soil_100 = soil.filter(regex='100cm$').copy()\n",
    "soil_100['site_reference'] = soil['site_refer'].values\n",
    "ctx_all = ctx_all.merge(soil_100, on=\"site_reference\", how=\"left\", validate=\"m:1\")\n",
    "\n",
    "# Land cover (static)\n",
    "landcover = landcover.rename(columns={'site_refer':'site_reference',\n",
    "                                      'land_cover_code':'land_cover'})\n",
    "landcover = landcover[['site_reference','land_cover']]\n",
    "ctx_all = ctx_all.merge(landcover, on=\"site_reference\", how=\"left\", validate=\"m:1\")\n",
    "\n",
    "# CO2 (year/month)\n",
    "co2_to_merge = cont[['year','month','value']].drop_duplicates(subset=['year','month']).rename(columns={'value':'co2_cont'})\n",
    "ctx_all = ctx_all.merge(co2_to_merge, on=['year','month'], how='left', validate=\"m:1\")\n",
    "\n",
    "# ALT (site/year)\n",
    "alt_to_merge = alt[['site_reference','year','ALT']].drop_duplicates(subset=['site_reference','year'])\n",
    "ctx_all = ctx_all.merge(alt_to_merge, on=['site_reference','year'], how='left', validate=\"m:1\")\n",
    "\n",
    "# Soil moisture (site/year/month)\n",
    "needed_cols = {'site_reference','year','month','sm_surface','sm_rootzone'}\n",
    "missing = needed_cols.difference(set(sm.columns))\n",
    "if missing:\n",
    "    raise ValueError(f\"Soil moisture CSV missing columns: {missing}\")\n",
    "ctx_all = ctx_all.merge(\n",
    "    sm[['site_reference','year','month','sm_surface','sm_rootzone']],\n",
    "    on=['site_reference','year','month'], how='left', validate='m:1'\n",
    ")\n",
    "\n",
    "# Land cover type cast\n",
    "if 'land_cover' in ctx_all.columns:\n",
    "    ctx_all['land_cover'] = ctx_all['land_cover'].fillna(-9999).astype(int)\n",
    "\n",
    "# --------- Save ---------\n",
    "Path(OUT_CSV).parent.mkdir(parents=True, exist_ok=True)\n",
    "ctx_all.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(\"Saved:\", OUT_CSV)\n",
    "print(ctx_all[['site_reference','year','month','tmmn','tmmx','tmean_C','pr','NDVI',\n",
    "               'temp_ctx','pr_ctx','ndvi_ctx',\n",
    "               'snow_cover','snow_cover_ctx',\n",
    "               'snow_depth','snow_depth_ctx',\n",
    "               'NDSI_snow_cover','ndsi_snow_cover_ctx']].head(12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29a090bb-39d5-4da3-a303-6ff9d19acaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_2878948/4179303193.py:3: DtypeWarning: Columns (47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df0 = pd.read_csv(\"/explore/nobackup/people/spotter5/anna_v/v2/v2_model_training_data_v4.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>nee</th>\n",
       "      <th>tmean_C</th>\n",
       "      <th>pr</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>snow_cover</th>\n",
       "      <th>snow_depth</th>\n",
       "      <th>NDSI_snow_cover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16079</th>\n",
       "      <td>2001</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.20</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.2739</td>\n",
       "      <td>0.590437</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>-9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18223</th>\n",
       "      <td>2001</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.70</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>1.989337</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>-9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28529</th>\n",
       "      <td>2002</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.65</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5478</td>\n",
       "      <td>1.012882</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>-9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30673</th>\n",
       "      <td>2002</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.15</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.5426</td>\n",
       "      <td>3.026446</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>-9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32816</th>\n",
       "      <td>2002</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.50</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.4426</td>\n",
       "      <td>5.878448</td>\n",
       "      <td>0.005916</td>\n",
       "      <td>-9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637713</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-24.95</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.447266</td>\n",
       "      <td>0.646442</td>\n",
       "      <td>-9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639362</th>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-16.70</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.447266</td>\n",
       "      <td>0.596106</td>\n",
       "      <td>-9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640335</th>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.256988</td>\n",
       "      <td>0.391686</td>\n",
       "      <td>-9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641744</th>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12.55</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.447266</td>\n",
       "      <td>0.207726</td>\n",
       "      <td>-9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643540</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.447266</td>\n",
       "      <td>0.306049</td>\n",
       "      <td>-9999.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        year  month  nee  tmean_C    pr    NDVI  snow_cover  snow_depth  \\\n",
       "16079   2001      7  NaN     4.20  36.0  0.2739    0.590437    0.000524   \n",
       "18223   2001      8  NaN     2.70  33.0  0.3450    1.989337    0.001972   \n",
       "28529   2002      7  NaN     4.65   2.0  0.5478    1.012882    0.001026   \n",
       "30673   2002      8  NaN     3.15  23.0  0.5426    3.026446    0.003077   \n",
       "32816   2002      9  NaN     2.50  51.0  0.4426    5.878448    0.005916   \n",
       "...      ...    ...  ...      ...   ...     ...         ...         ...   \n",
       "637713  2024      3  NaN   -24.95   3.0     NaN   98.447266    0.646442   \n",
       "639362  2024      4  NaN   -16.70   7.0     NaN   98.447266    0.596106   \n",
       "640335  2024      5  NaN    -6.00   5.0     NaN   98.256988    0.391686   \n",
       "641744  2024     11  NaN   -12.55  11.0     NaN   98.447266    0.207726   \n",
       "643540  2024     12  NaN   -21.25   2.0     NaN   98.447266    0.306049   \n",
       "\n",
       "        NDSI_snow_cover  \n",
       "16079           -9999.0  \n",
       "18223           -9999.0  \n",
       "28529           -9999.0  \n",
       "30673           -9999.0  \n",
       "32816           -9999.0  \n",
       "...                 ...  \n",
       "637713          -9999.0  \n",
       "639362          -9999.0  \n",
       "640335          -9999.0  \n",
       "641744          -9999.0  \n",
       "643540          -9999.0  \n",
       "\n",
       "[288 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df0 = pd.read_csv(\"/explore/nobackup/people/spotter5/anna_v/v2/v2_model_training_data_v4.csv\")\n",
    "\n",
    "df0.columns\n",
    "\n",
    "df0 = df0[df0['year'] >= 2001]\n",
    "site_ref = 'ARM-NSA-Barrow_US-A10_tower'\n",
    "#'Zackenberg Heath_GL-ZaH_tower'\n",
    "df0 = df0[df0['site_reference'] == site_ref]\n",
    "\n",
    "\n",
    "df0['tmean_C'] = df0[['tmmn', 'tmmx']].mean(axis=1)\n",
    "df0 = df0[['year', 'month', 'nee', 'tmean_C', 'pr', 'NDVI', 'snow_cover', 'snow_depth', 'NDSI_snow_cover']]\n",
    "df0['year'] = df0['year'].astype(int)\n",
    "df0['month'] = df0['month'].astype(int)\n",
    "\n",
    "# # Collapse duplicates to monthly means (if duplicates exist for a month)\n",
    "monthly = (\n",
    "    df0.groupby(['year', 'month'], as_index=False)\n",
    "       .agg({'tmean_C':'mean', 'pr':'mean'})\n",
    "       .sort_values(['year','month'])\n",
    ")\n",
    "\n",
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c709677-3068-470b-bce0-a6314cd4ea58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9999.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0['NDSI_snow_cover'].unique()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4adac2ca-bc0f-4977-986d-2d7a80975624",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "666f294b-6ece-49a1-a626-ee533b90d799",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_2878948/2896960024.py:3: DtypeWarning: Columns (47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df0 = pd.read_csv(\"/explore/nobackup/people/spotter5/anna_v/v2/v2_model_training_data_v4.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>nee</th>\n",
       "      <th>tmean_C</th>\n",
       "      <th>pr</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>Percent_Tree_Cover</th>\n",
       "      <th>Percent_NonVegetated</th>\n",
       "      <th>Percent_NonTree_Vegetation</th>\n",
       "      <th>snow_cover</th>\n",
       "      <th>snow_depth</th>\n",
       "      <th>NDSI_snow_cover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13230</th>\n",
       "      <td>2001</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.95</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.5581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.636637</td>\n",
       "      <td>8.730915e-02</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14695</th>\n",
       "      <td>2001</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.00</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.5608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.325456</td>\n",
       "      <td>3.390842e-04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16594</th>\n",
       "      <td>2001</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.70</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.4922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.345365e-24</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18738</th>\n",
       "      <td>2001</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.25</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.7397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024267</td>\n",
       "      <td>3.543977e-05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20874</th>\n",
       "      <td>2001</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.80</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.7130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.153402</td>\n",
       "      <td>1.242405e-03</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634070</th>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-16.20</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.802734</td>\n",
       "      <td>5.982955e-01</td>\n",
       "      <td>-9999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636073</th>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-11.55</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.802734</td>\n",
       "      <td>6.621388e-01</td>\n",
       "      <td>63.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637793</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.60</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.802734</td>\n",
       "      <td>6.315695e-01</td>\n",
       "      <td>65.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639430</th>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.10</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.802734</td>\n",
       "      <td>7.083618e-01</td>\n",
       "      <td>71.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643665</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-11.05</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.802734</td>\n",
       "      <td>3.487983e-01</td>\n",
       "      <td>-9999.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        year  month  nee  tmean_C     pr    NDVI  Percent_Tree_Cover  \\\n",
       "13230   2001      5  NaN     1.95   24.0  0.5581                 0.0   \n",
       "14695   2001      6  NaN    11.00   33.0  0.5608                 0.0   \n",
       "16594   2001      7  NaN    12.70  138.0  0.4922                 0.0   \n",
       "18738   2001      8  NaN    10.25   87.0  0.7397                 0.0   \n",
       "20874   2001      9  NaN     6.80   44.0  0.7130                 0.0   \n",
       "...      ...    ...  ...      ...    ...     ...                 ...   \n",
       "634070  2024      1  NaN   -16.20   37.0     NaN                 0.0   \n",
       "636073  2024      2  NaN   -11.55   24.0     NaN                 0.0   \n",
       "637793  2024      3  NaN    -7.60   23.0     NaN                 0.0   \n",
       "639430  2024      4  NaN    -6.10   29.0     NaN                 0.0   \n",
       "643665  2024     12  NaN   -11.05   37.0     NaN                 0.0   \n",
       "\n",
       "        Percent_NonVegetated  Percent_NonTree_Vegetation  snow_cover  \\\n",
       "13230                  100.0                         0.0   46.636637   \n",
       "14695                  100.0                         0.0    0.325456   \n",
       "16594                  100.0                         0.0    0.000000   \n",
       "18738                  100.0                         0.0    0.024267   \n",
       "20874                  100.0                         0.0    1.153402   \n",
       "...                      ...                         ...         ...   \n",
       "634070                 100.0                         0.0   95.802734   \n",
       "636073                 100.0                         0.0   95.802734   \n",
       "637793                 100.0                         0.0   95.802734   \n",
       "639430                 100.0                         0.0   95.802734   \n",
       "643665                 100.0                         0.0   95.802734   \n",
       "\n",
       "          snow_depth  NDSI_snow_cover  \n",
       "13230   8.730915e-02        50.000000  \n",
       "14695   3.390842e-04         0.000000  \n",
       "16594  -7.345365e-24         0.000000  \n",
       "18738   3.543977e-05         0.000000  \n",
       "20874   1.242405e-03        10.000000  \n",
       "...              ...              ...  \n",
       "634070  5.982955e-01     -9999.000000  \n",
       "636073  6.621388e-01        63.900000  \n",
       "637793  6.315695e-01        65.444444  \n",
       "639430  7.083618e-01        71.142857  \n",
       "643665  3.487983e-01     -9999.000000  \n",
       "\n",
       "[288 rows x 12 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df0 = pd.read_csv(\"/explore/nobackup/people/spotter5/anna_v/v2/v2_model_training_data_v4.csv\")\n",
    "\n",
    "df0.columns\n",
    "\n",
    "df0 = df0[df0['year'] >= 2001]\n",
    "site_ref = 'ARM-NSA-Barrow_US-A10_tower'\n",
    "#'Zackenberg Heath_GL-ZaH_tower'\n",
    "site_ref = 'Iskoras_NO-Isk-fen_tower'\n",
    "df0 = df0[df0['site_reference'] == site_ref]\n",
    "\n",
    "\n",
    "df0['tmean_C'] = df0[['tmmn', 'tmmx']].mean(axis=1)\n",
    "df0 = df0[['year', 'month', 'nee', 'tmean_C', 'pr', 'NDVI', 'Percent_Tree_Cover', \n",
    "           'Percent_NonVegetated', 'Percent_NonTree_Vegetation', 'snow_cover', 'snow_depth', 'NDSI_snow_cover']]\n",
    "df0['year'] = df0['year'].astype(int)\n",
    "df0['month'] = df0['month'].astype(int)\n",
    "\n",
    "# # Collapse duplicates to monthly means (if duplicates exist for a month)\n",
    "# monthly = (\n",
    "#     df0.groupby(['year', 'month'], as_index=False)\n",
    "#        .agg({'tmean_C':'mean', 'pr':'mean'})\n",
    "#        .sort_values(['year','month'])\n",
    "# )\n",
    "\n",
    "\n",
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99d910ac-6be6-4563-8153-ba9097fd7ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0['Percent_Tree_Cover'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1d103a-3e76-4be4-8521-ebbed2ef9f43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-xgboost_gpu]",
   "language": "python",
   "name": "conda-env-.conda-xgboost_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "239ba8d7-2bae-4990-8f31-2f4ff0d661d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "RUNNING TUNED CATBOOST (GPU) ANALYSIS FOR: NEE\n",
      "==================================================\n",
      "--- Processing Target: NEE ---\n",
      "  Processing site: Fyodorovskoye_RU-Fyo_tower...\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 36 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n36 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/catboost/core.py\", line 5873, in fit\n    return self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline,\n  File \"/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/catboost/core.py\", line 2395, in _fit\n    train_params = self._prepare_train_params(\n  File \"/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/catboost/core.py\", line 2321, in _prepare_train_params\n    _check_train_params(params)\n  File \"_catboost.pyx\", line 6601, in _catboost._check_train_params\n  File \"_catboost.pyx\", line 6623, in _catboost._check_train_params\n_catboost.CatBoostError: catboost/private/libs/options/catboost_options.cpp:794: Error: default bootstrap type (bayesian) doesn't support 'subsample' option\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 172\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m target \u001b[38;5;129;01min\u001b[39;00m targets_to_run:\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRUNNING TUNED CATBOOST (GPU) ANALYSIS FOR: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m     \u001b[43mrun_loso_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCOMPLETED TUNED CATBOOST (GPU) ANALYSIS FOR: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 109\u001b[0m, in \u001b[0;36mrun_loso_analysis\u001b[0;34m(target_col)\u001b[0m\n\u001b[1;32m    100\u001b[0m inner_cv \u001b[38;5;241m=\u001b[39m KFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m    101\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m    102\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    103\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    108\u001b[0m )\n\u001b[0;32m--> 109\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# --- C. EVALUATE ON THE OUTER TEST SET ---\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Best params for this fold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1014\u001b[0m     )\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1018\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1572\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1572\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/sklearn/model_selection/_search.py:995\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    993\u001b[0m     )\n\u001b[0;32m--> 995\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[0;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    539\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 36 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n36 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/catboost/core.py\", line 5873, in fit\n    return self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline,\n  File \"/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/catboost/core.py\", line 2395, in _fit\n    train_params = self._prepare_train_params(\n  File \"/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/catboost/core.py\", line 2321, in _prepare_train_params\n    _check_train_params(params)\n  File \"_catboost.pyx\", line 6601, in _catboost._check_train_params\n  File \"_catboost.pyx\", line 6623, in _catboost._check_train_params\n_catboost.CatBoostError: catboost/private/libs/options/catboost_options.cpp:794: Error: default bootstrap type (bayesian) doesn't support 'subsample' option\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Suppress warnings\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore::FutureWarning'\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "def run_loso_analysis(target_col):\n",
    "    \"\"\"\n",
    "    Performs a full Leave-One-Site-Out (LOSO) cross-validation for a given target variable\n",
    "    using CatBoost with nested cross-validation for hyperparameter tuning on a GPU.\n",
    "\n",
    "    Args:\n",
    "        target_col (str): The name of the target variable column (e.g., 'gpp', 'nee').\n",
    "    \"\"\"\n",
    "    # 1. Load and prepare dataset\n",
    "    print(f\"--- Processing Target: {target_col.upper()} ---\")\n",
    "    file_path = \"/explore/nobackup/people/spotter5/anna_v/v2/v2_model_training_final.csv\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['land_cover'] = df['land_cover'].astype('category')\n",
    "    df['month'] = df['month'].astype('category')\n",
    "    df = df[df['flux_method'] == 'EC']\n",
    "\n",
    "    # 2. Create derived features\n",
    "    df['tmean_C'] = df[['tmmn', 'tmmx']].mean(axis=1)\n",
    "    df['date'] = pd.to_datetime(df[['year', 'month']].assign(day=1))\n",
    "\n",
    "    # 3. Define predictors\n",
    "    feature_cols = [\n",
    "        'EVI', 'NDVI', 'sur_refl_b01', 'sur_refl_b02', 'sur_refl_b03',\n",
    "        'sur_refl_b07', 'NDWI', 'pdsi', 'srad', 'tmean_C', 'vap', 'vs',\n",
    "        'bdod_0_100cm', 'cec_0_100cm', 'cfvo_0_100cm', 'clay_0_100cm',\n",
    "        'nitrogen_0_100cm', 'ocd_0_100cm', 'phh2o_0_100cm', 'sand_0_100cm',\n",
    "        'silt_0_100cm', 'soc_0_100cm', 'co2_cont', 'ALT',\n",
    "        'land_cover', 'month',\n",
    "        'lai', 'fpar', 'Percent_NonTree_Vegetation',\n",
    "        'Percent_NonVegetated', 'Percent_Tree_Cover'\n",
    "    ]\n",
    "    categorical_features_names = ['land_cover', 'month']\n",
    "    \n",
    "    # Drop rows where the current target or site_reference is missing\n",
    "    df = df.dropna(subset=['site_reference', target_col])\n",
    "\n",
    "    # 4. Define output paths\n",
    "    loocv_out_path = os.path.join(\"/explore/nobackup/people/spotter5/anna_v/v2/loocv\", target_col)\n",
    "    figures_path = os.path.join(loocv_out_path, \"figures_catboost_tuned_gpu\")\n",
    "    models_out_path = '/explore/nobackup/people/spotter5/anna_v/v2/models'\n",
    "    os.makedirs(loocv_out_path, exist_ok=True)\n",
    "    os.makedirs(figures_path, exist_ok=True)\n",
    "    os.makedirs(models_out_path, exist_ok=True)\n",
    "\n",
    "    # 5. Prepare features (X) and target (y)\n",
    "    X = df[feature_cols].copy()\n",
    "    y = df[target_col]\n",
    "    sites = df[\"site_reference\"].unique()\n",
    "\n",
    "    results = []\n",
    "    all_preds_df_list = []\n",
    "\n",
    "    # 6. Nested CV: Outer loop is LOSO, Inner loop is GridSearchCV for tuning\n",
    "    for test_site in sites:\n",
    "        print(f\"  Processing site: {test_site}...\")\n",
    "        train_idx = df[\"site_reference\"] != test_site\n",
    "        test_idx = df[\"site_reference\"] == test_site\n",
    "\n",
    "        if test_idx.sum() < 1:\n",
    "            continue\n",
    "\n",
    "        X_train, y_train = X.loc[train_idx], y.loc[train_idx]\n",
    "        X_test, y_test = X.loc[test_idx], y.loc[test_idx]\n",
    "        dates_test = df.loc[test_idx, \"date\"]\n",
    "\n",
    "        # --- A. DEFINE THE MODEL AND PARAMETER GRID FOR TUNING ---\n",
    "        model = CatBoostRegressor(\n",
    "            random_state=42,\n",
    "            verbose=0,\n",
    "            allow_writing_files=False,\n",
    "            cat_features=categorical_features_names,\n",
    "            task_type='GPU',\n",
    "            bootstrap_type='Bernoulli'  # **FIX**: Added to support the 'subsample' parameter\n",
    "        )\n",
    "        \n",
    "        param_grid = {\n",
    "            'iterations': [1200],\n",
    "            'depth': [5, 8, 12],\n",
    "            'learning_rate': [0.01],\n",
    "            'subsample': [0.7, 0.9],\n",
    "            'l2_leaf_reg': [0.01, 1]\n",
    "        }\n",
    "\n",
    "        # --- B. SETUP AND RUN THE INNER CROSS-VALIDATION (GRID SEARCH) ---\n",
    "        inner_cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grid,\n",
    "            cv=inner_cv,\n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # --- C. EVALUATE ON THE OUTER TEST SET ---\n",
    "        print(f\"    Best params for this fold: {grid_search.best_params_}\")\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "        site_df = pd.DataFrame({\"Site\": test_site, \"Date\": dates_test.values, \"Observed\": y_test.values, \"Predicted\": y_pred})\n",
    "        all_preds_df_list.append(site_df)\n",
    "        \n",
    "        results.append({\n",
    "            \"Site\": test_site,\n",
    "            \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "            \"MAE\": mean_absolute_error(y_test, y_pred),\n",
    "            \"R2\": r2_score(y_test, y_pred),\n",
    "            \"Best_Params\": str(grid_search.best_params_)\n",
    "        })\n",
    "\n",
    "    # 7. Combine, Save, and Report Results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    all_preds_df = pd.concat(all_preds_df_list, ignore_index=True)\n",
    "\n",
    "    results_csv_path = os.path.join(loocv_out_path, f'catboost_tuned_gpu_results_{target_col}.csv')\n",
    "    predictions_csv_path = os.path.join(loocv_out_path, f'catboost_tuned_gpu_predictions_{target_col}.csv')\n",
    "    results_df.to_csv(results_csv_path, index=False)\n",
    "    all_preds_df.to_csv(predictions_csv_path, index=False)\n",
    "    print(f\"\\n  Tuned CatBoost (GPU) results saved to: {results_csv_path}\")\n",
    "\n",
    "    rmse_all = np.sqrt(mean_squared_error(all_preds_df[\"Observed\"], all_preds_df[\"Predicted\"]))\n",
    "    r2_all = r2_score(all_preds_df[\"Observed\"], all_preds_df[\"Predicted\"])\n",
    "    mae_all = mean_absolute_error(all_preds_df[\"Observed\"], all_preds_df[\"Predicted\"])\n",
    "    print(f\"\\n  --- Pooled Metrics for Tuned CatBoost (GPU): {target_col.upper()} ---\")\n",
    "    print(f\"  Pooled RÂ²: {r2_all:.4f}, Pooled RMSE: {rmse_all:.4f}, Pooled MAE: {mae_all:.4f}\")\n",
    "\n",
    "    # 8. Plotting (Code would go here)\n",
    "\n",
    "    # 9. Find Best Params on ALL Data and Save Final Model\n",
    "    print(\"\\n  Finding best params and training final model on all data...\")\n",
    "    final_model_base = CatBoostRegressor(\n",
    "        random_state=42,\n",
    "        verbose=0,\n",
    "        allow_writing_files=False,\n",
    "        cat_features=categorical_features_names,\n",
    "        task_type='GPU',\n",
    "        bootstrap_type='Bernoulli'  # **FIX**: Added to support the 'subsample' parameter\n",
    "    )\n",
    "    final_cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    final_grid_search = GridSearchCV(estimator=final_model_base, param_grid=param_grid, cv=final_cv, scoring='neg_root_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "    final_grid_search.fit(X, y)\n",
    "    \n",
    "    print(f\"  --- Best params for final model: {final_grid_search.best_params_} ---\")\n",
    "    final_model = final_grid_search.best_estimator_\n",
    "    \n",
    "    model_filename = os.path.join(models_out_path, f'catboost_tuned_gpu_{target_col}.json')\n",
    "    final_model.save_model(model_filename)\n",
    "    print(f\"  Final tuned CatBoost (GPU) model saved to: {model_filename}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    targets_to_run = ['gpp', 'nee', 'reco', 'ch4_flux_total']\n",
    "\n",
    "    for target in targets_to_run:\n",
    "        print(f\"\\n{'='*50}\\nRUNNING TUNED CATBOOST (GPU) ANALYSIS FOR: {target.upper()}\\n{'='*50}\")\n",
    "        run_loso_analysis(target_col=target)\n",
    "        print(f\"\\n{'='*50}\\nCOMPLETED TUNED CATBOOST (GPU) ANALYSIS FOR: {target.upper()}\\n{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819dc288-c359-4b60-903b-9fe29a50a0be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-xgboost_gpu]",
   "language": "python",
   "name": "conda-env-.conda-xgboost_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

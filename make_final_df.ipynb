{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "165e9317-90a1-4278-a30a-c4b3b14bba9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_129052/2546976097.py:5: DtypeWarning: Columns (47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  input_data = pd.read_csv(\"/explore/nobackup/people/spotter5/anna_v/v2/v2_model_training_data_v4.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape: (56731, 51)\n",
      "After soil merge: (56731, 61)\n",
      "After landcover merge: (56731, 62)\n",
      "After CO2 merge: (56731, 63)\n",
      "After ALT merge: (56731, 64)\n",
      "After soil moisture merge: (56731, 66)\n",
      "\n",
      "Successfully merged all data and saved to: /explore/nobackup/people/spotter5/anna_v/v2/v2_model_training_final.csv\n",
      "Final DataFrame head:\n",
      "                                           site_name  \\\n",
      "0                                         Skyttorp 2   \n",
      "1                                  Wolf_creek_forest   \n",
      "2  Alberta - Western Peatland - LaBiche River,Bla...   \n",
      "3                             Elgeeii forest station   \n",
      "4                                           Faejemyr   \n",
      "\n",
      "                                      site_reference   latitude   longitude  \\\n",
      "0                            Skyttorp 2_SE-Sk2_tower  60.129667   17.840056   \n",
      "1                     Wolf_creek_forest_CA-WCF_tower  60.596886 -134.952833   \n",
      "2  Alberta - Western Peatland - LaBiche River,Bla...  54.953840 -112.466980   \n",
      "3                Elgeeii forest station_RU-Ege_tower  60.015516  133.824012   \n",
      "4                              Faejemyr_SE-Faj_tower  56.265500   13.553500   \n",
      "\n",
      "  flux_method country  land_cover_eco  land_cover_plot    bawld_class  year  \\\n",
      "0          EC  Sweden            70.0             70.0  Boreal Forest  2000   \n",
      "1          EC  Canada            70.0             70.0  Boreal Forest  2000   \n",
      "2          EC  Canada           160.0            160.0            Fen  2000   \n",
      "3          EC  Russia            90.0             90.0  Boreal Forest  2000   \n",
      "4          EC  Sweden           180.0            180.0            Bog  2000   \n",
      "\n",
      "   ...  ocd_0_100cm phh2o_0_100cm  sand_0_100cm  silt_0_100cm  soc_0_100cm  \\\n",
      "0  ...          NaN           NaN           NaN           NaN          NaN   \n",
      "1  ...    21.602915      7.352632     55.487802     28.810267    11.866563   \n",
      "2  ...    13.246189      6.252252     50.121325     30.162230    35.182187   \n",
      "3  ...    17.086907      7.130071     41.499711     31.082185    53.577813   \n",
      "4  ...          NaN           NaN           NaN           NaN          NaN   \n",
      "\n",
      "   land_cover  co2_cont   ALT  sm_surface  sm_rootzone  \n",
      "0           7    376.89   NaN    0.339861     0.331989  \n",
      "1           6    376.89  1.10    0.253667     0.185445  \n",
      "2           1    374.96   NaN    0.187536     0.207688  \n",
      "3           4    374.96  1.25    0.158696     0.128285  \n",
      "4          13    374.96   NaN    0.343885     0.308715  \n",
      "\n",
      "[5 rows x 66 columns]\n",
      "\n",
      "Final DataFrame columns:\n",
      "Index(['site_name', 'site_reference', 'latitude', 'longitude', 'flux_method',\n",
      "       'country', 'land_cover_eco', 'land_cover_plot', 'bawld_class', 'year',\n",
      "       'month', 'siteID', 'EVI', 'NDVI', 'SummaryQA', 'sur_refl_b01',\n",
      "       'sur_refl_b02', 'sur_refl_b03', 'sur_refl_b07', 'NDWI', 'aet', 'def',\n",
      "       'pdsi', 'pet', 'pr', 'ro', 'soil', 'srad', 'swe', 'tmmn', 'tmmx', 'vap',\n",
      "       'vpd', 'vs', 'lai', 'fpar', 'Percent_NonTree_Vegetation',\n",
      "       'Percent_NonVegetated', 'Percent_Tree_Cover', 'snow_cover',\n",
      "       'snow_depth', 'NDSI_snow_cover', 'nee', 'gpp', 'reco', 'ch4_flux_total',\n",
      "       'expert_flag_co2', 'expert_flag_ch4', 'expert_flag_gpp',\n",
      "       'expert_flag_reco', 'Flux', 'bdod_0_100cm', 'cec_0_100cm',\n",
      "       'cfvo_0_100cm', 'clay_0_100cm', 'nitrogen_0_100cm', 'ocd_0_100cm',\n",
      "       'phh2o_0_100cm', 'sand_0_100cm', 'silt_0_100cm', 'soc_0_100cm',\n",
      "       'land_cover', 'co2_cont', 'ALT', 'sm_surface', 'sm_rootzone'],\n",
      "      dtype='object')\n",
      "\n",
      "Data type of 'land_cover' column: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Load all data sources ---\n",
    "input_data = pd.read_csv(\"/explore/nobackup/people/spotter5/anna_v/v2/v2_model_training_data_v4.csv\")\n",
    "soil       = pd.read_csv(\"/explore/nobackup/people/spotter5/anna_v/v2/integrated_soil_data_1km_v2_sites.csv\")\n",
    "landcover  = pd.read_csv(\"/explore/nobackup/people/spotter5/anna_v/v2/extracted_landcover_values_v2.csv\")\n",
    "# keep these for potential use, but we’ll rename properly below\n",
    "landcover  = landcover[['site_refer', 'land_cover_code']]\n",
    "\n",
    "sm         = pd.read_csv(\"/explore/nobackup/people/spotter5/anna_v/v2/soil_moisture_by_site_monthly_2000_2023.csv\")\n",
    "cont       = pd.read_csv(\"/explore/nobackup/people/spotter5/anna_v/v2/co2_cont.csv\")\n",
    "alt        = pd.read_csv(\"/explore/nobackup/people/spotter5/anna_v/v2/ALT_by_site.csv\")\n",
    "\n",
    "# --- Initial Data Cleaning ---\n",
    "# Keep EC only, drop rows without site_reference\n",
    "input_data = input_data[input_data['flux_method'] == 'EC'].copy()\n",
    "input_data = input_data.dropna(subset=['site_reference'])\n",
    "\n",
    "# Drop rows without keys in other tables\n",
    "soil      = soil.dropna(subset=['site_refer']).copy()\n",
    "landcover = landcover.dropna(subset=['site_refer']).copy()\n",
    "\n",
    "# Ensure key types are consistent before merging\n",
    "for df in [input_data, alt, sm]:\n",
    "    if 'site_reference' in df.columns:\n",
    "        df['site_reference'] = df['site_reference'].astype(str)\n",
    "for df in [soil, landcover]:\n",
    "    if 'site_refer' in df.columns:\n",
    "        df['site_refer'] = df['site_refer'].astype(str)\n",
    "\n",
    "for df in [input_data, alt, sm, cont]:\n",
    "    if 'year' in df.columns:\n",
    "        df['year'] = pd.to_numeric(df['year'], errors='coerce').astype('Int64')\n",
    "    if 'month' in df.columns:\n",
    "        df['month'] = pd.to_numeric(df['month'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Deduplicate on merge keys\n",
    "input_data = input_data.drop_duplicates(subset=['site_reference', 'year', 'month'])\n",
    "soil       = soil.drop_duplicates(subset=['site_refer'])\n",
    "landcover  = landcover.drop_duplicates(subset=['site_refer'])\n",
    "alt        = alt.drop_duplicates(subset=['site_reference', 'year'])\n",
    "sm         = sm.drop_duplicates(subset=['site_reference', 'year', 'month'])\n",
    "\n",
    "print(f\"Initial shape: {input_data.shape}\")\n",
    "\n",
    "# --- Prepare and Merge Soil (static) ---\n",
    "# keep only 100 cm depth columns; carry site_reference for join\n",
    "soil_filtered = soil.filter(regex='100cm$').copy()\n",
    "soil_filtered[\"site_reference\"] = soil[\"site_refer\"].values\n",
    "input_data = input_data.merge(soil_filtered, on=\"site_reference\", how=\"left\", validate=\"m:1\")\n",
    "print(f\"After soil merge: {input_data.shape}\")\n",
    "\n",
    "# --- Prepare and Merge Land Cover (static) ---\n",
    "# rename to match keys and column you want in final data\n",
    "landcover = landcover.rename(columns={'site_refer': 'site_reference',\n",
    "                                      'land_cover_code': 'land_cover'})\n",
    "# keep only the necessary columns (keep lat/lon too if you want them in final)\n",
    "landcover = landcover[['site_reference', 'land_cover']]\n",
    "input_data = input_data.merge(landcover, on=\"site_reference\", how=\"left\", validate=\"m:1\")\n",
    "print(f\"After landcover merge: {input_data.shape}\")\n",
    "\n",
    "# --- Prepare and Merge CO2 (time-varying by year/month) ---\n",
    "co2_to_merge = cont[['year', 'month', 'value']].copy()\n",
    "co2_to_merge = co2_to_merge.rename(columns={'value': 'co2_cont'})\n",
    "co2_to_merge = co2_to_merge.drop_duplicates(subset=['year', 'month'])\n",
    "input_data = input_data.merge(co2_to_merge, on=['year', 'month'], how='left', validate=\"m:1\")\n",
    "print(f\"After CO2 merge: {input_data.shape}\")\n",
    "\n",
    "# --- Prepare and Merge ALT (time-varying by site/year) ---\n",
    "alt_to_merge = alt[['site_reference', 'year', 'ALT']].copy()\n",
    "alt_to_merge = alt_to_merge.drop_duplicates(subset=['site_reference', 'year'])\n",
    "input_data = input_data.merge(alt_to_merge, on=['site_reference', 'year'], how='left', validate=\"m:1\")\n",
    "print(f\"After ALT merge: {input_data.shape}\")\n",
    "\n",
    "# --- Prepare and Merge Soil Moisture (time-varying by site/year/month) ---\n",
    "# Expecting columns: site_reference, year, month, sm_surface, sm_rootzone\n",
    "needed_cols = {'site_reference', 'year', 'month', 'sm_surface', 'sm_rootzone'}\n",
    "missing = needed_cols.difference(set(sm.columns))\n",
    "if missing:\n",
    "    raise ValueError(f\"Soil moisture CSV is missing expected columns: {missing}\")\n",
    "\n",
    "input_data = input_data.merge(\n",
    "    sm[['site_reference', 'year', 'month', 'sm_surface', 'sm_rootzone']],\n",
    "    on=['site_reference', 'year', 'month'],\n",
    "    how='left',\n",
    "    validate='m:1'\n",
    ")\n",
    "print(f\"After soil moisture merge: {input_data.shape}\")\n",
    "\n",
    "# --- Final Data Type Conversion for Land Cover ---\n",
    "# Fill any missing values (NaN) in 'land_cover' with -9999 and cast to int\n",
    "if 'land_cover' in input_data.columns:\n",
    "    input_data['land_cover'] = input_data['land_cover'].fillna(-9999).astype(int)\n",
    "\n",
    "# --- Save Final Combined Data ---\n",
    "output_path_final = \"/explore/nobackup/people/spotter5/anna_v/v2/v2_model_training_final.csv\"\n",
    "input_data.to_csv(output_path_final, index=False)\n",
    "\n",
    "print(f\"\\nSuccessfully merged all data and saved to: {output_path_final}\")\n",
    "print(\"Final DataFrame head:\")\n",
    "print(input_data.head())\n",
    "print(\"\\nFinal DataFrame columns:\")\n",
    "print(input_data.columns)\n",
    "if 'land_cover' in input_data.columns:\n",
    "    print(f\"\\nData type of 'land_cover' column: {input_data['land_cover'].dtype}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae019e67-8998-44d0-a3fc-8e0fe33453da",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/explore/nobackup/people/spotter5/anna_v/v2/v2_model_training_data_final.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m input_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/explore/nobackup/people/spotter5/anna_v/v2/v2_model_training_data_final.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m input_data \u001b[38;5;241m=\u001b[39m input_data[input_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msite_reference\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZackenberg Heath_GL-ZaH_tower\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m input_data \u001b[38;5;241m=\u001b[39m input_data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnee\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmmx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmmn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpr\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[0;32m~/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/explore/nobackup/people/spotter5/anna_v/v2/v2_model_training_data_final.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "input_data = pd.read_csv(\"/explore/nobackup/people/spotter5/anna_v/v2/v2_model_training_data_final.csv\")\n",
    "input_data = input_data[input_data['site_reference'] == 'Zackenberg Heath_GL-ZaH_tower']\n",
    "\n",
    "input_data = input_data[['year', 'month', 'nee', 'tmmx', 'tmmn', 'pr']]\n",
    "input_data.sort_values(by = 'year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81af1eca-23ec-4af4-adfa-c4c8057a483d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_reference</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>land_cover_eco</th>\n",
       "      <th>land_cover_plot</th>\n",
       "      <th>bawld_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skyttorp 2_SE-Sk2_tower</td>\n",
       "      <td>60.129667</td>\n",
       "      <td>17.840056</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Boreal Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wolf_creek_forest_CA-WCF_tower</td>\n",
       "      <td>60.596886</td>\n",
       "      <td>-134.952833</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Boreal Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alberta - Western Peatland - LaBiche River,Bla...</td>\n",
       "      <td>54.953840</td>\n",
       "      <td>-112.466980</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>Fen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elgeeii forest station_RU-Ege_tower</td>\n",
       "      <td>60.015516</td>\n",
       "      <td>133.824012</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Boreal Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Faejemyr_SE-Faj_tower</td>\n",
       "      <td>56.265500</td>\n",
       "      <td>13.553500</td>\n",
       "      <td>180.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>Bog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>ARM-NSA-Barrow_US-A10_tower</td>\n",
       "      <td>71.323000</td>\n",
       "      <td>-156.609000</td>\n",
       "      <td>153.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>Wet Tundra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>Barrow-CMDL_US-Brw_tower</td>\n",
       "      <td>71.322525</td>\n",
       "      <td>-156.609200</td>\n",
       "      <td>180.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>Wet Tundra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>Bayelva, Spitsbergen_SJ-Blv_tower</td>\n",
       "      <td>78.921600</td>\n",
       "      <td>11.831100</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>Dry Tundra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>Central Marsh_US-Cms_tower</td>\n",
       "      <td>71.320190</td>\n",
       "      <td>-156.622270</td>\n",
       "      <td>180.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>Wet Tundra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>Finse west_NO-Fns_tower</td>\n",
       "      <td>60.110000</td>\n",
       "      <td>7.530000</td>\n",
       "      <td>120.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>Wet Tundra</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        site_reference   latitude   longitude  \\\n",
       "0                              Skyttorp 2_SE-Sk2_tower  60.129667   17.840056   \n",
       "1                       Wolf_creek_forest_CA-WCF_tower  60.596886 -134.952833   \n",
       "2    Alberta - Western Peatland - LaBiche River,Bla...  54.953840 -112.466980   \n",
       "3                  Elgeeii forest station_RU-Ege_tower  60.015516  133.824012   \n",
       "4                                Faejemyr_SE-Faj_tower  56.265500   13.553500   \n",
       "..                                                 ...        ...         ...   \n",
       "429                        ARM-NSA-Barrow_US-A10_tower  71.323000 -156.609000   \n",
       "445                           Barrow-CMDL_US-Brw_tower  71.322525 -156.609200   \n",
       "446                  Bayelva, Spitsbergen_SJ-Blv_tower  78.921600   11.831100   \n",
       "457                         Central Marsh_US-Cms_tower  71.320190 -156.622270   \n",
       "476                            Finse west_NO-Fns_tower  60.110000    7.530000   \n",
       "\n",
       "     land_cover_eco  land_cover_plot    bawld_class  \n",
       "0              70.0             70.0  Boreal Forest  \n",
       "1              70.0             70.0  Boreal Forest  \n",
       "2             160.0            160.0            Fen  \n",
       "3              90.0             90.0  Boreal Forest  \n",
       "4             180.0            180.0            Bog  \n",
       "..              ...              ...            ...  \n",
       "429           153.0            153.0     Wet Tundra  \n",
       "445           180.0            180.0     Wet Tundra  \n",
       "446           130.0            130.0     Dry Tundra  \n",
       "457           180.0            180.0     Wet Tundra  \n",
       "476           120.0            120.0     Wet Tundra  \n",
       "\n",
       "[188 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "input_data = pd.read_csv(\"/explore/nobackup/people/spotter5/anna_v/v2/v2_model_training_final.csv\")\n",
    "input_data = input_data.drop_duplicates(subset = 'site_reference')\n",
    "\n",
    "input_data = input_data[['site_reference', 'latitude', 'longitude', 'land_cover_eco', 'land_cover_plot', 'bawld_class']]\n",
    "input_data\n",
    "\n",
    "# input_data = input_data[['year', 'month', 'nee', 'tmmx', 'tmmn', 'pr']]\n",
    "# input_data.sort_values(by = 'year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1011045-98b9-4449-9853-e10edb5f56b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['site_name', 'site_reference', 'latitude', 'longitude', 'flux_method',\n",
       "       'country', 'land_cover_eco', 'land_cover_plot', 'bawld_class', 'year',\n",
       "       'month', 'siteID', 'EVI', 'NDVI', 'SummaryQA', 'sur_refl_b01',\n",
       "       'sur_refl_b02', 'sur_refl_b03', 'sur_refl_b07', 'NDWI', 'aet', 'def',\n",
       "       'pdsi', 'pet', 'pr', 'ro', 'soil', 'srad', 'swe', 'tmmn', 'tmmx', 'vap',\n",
       "       'vpd', 'vs', 'lai', 'fpar', 'Percent_NonTree_Vegetation',\n",
       "       'Percent_NonVegetated', 'Percent_Tree_Cover', 'nee', 'gpp', 'reco',\n",
       "       'ch4_flux_total', 'Flux'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbc9b3c-f0ab-484f-b2f6-0c5e571d9303",
   "metadata": {},
   "source": [
    "same thing but use thew 16day modis data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50cf0d95-6620-467b-925a-d68f7dbaa0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape: (56731, 39)\n",
      "After replacing reflectance bands: (56731, 43)\n",
      "After soil merge: (56731, 53)\n",
      "After landcover merge: (56731, 54)\n",
      "After CO2 merge: (56731, 55)\n",
      "After ALT merge: (56731, 56)\n",
      "\n",
      "Successfully merged all data and saved to: /explore/nobackup/people/spotter5/anna_v/v2/v2_model_training_final_mod16.csv\n",
      "Final DataFrame head:\n",
      "                                           site_name  \\\n",
      "0                                     ARM-NSA-Barrow   \n",
      "1                                    ARM-NSA-Oliktok   \n",
      "2                      Abisko Stordalen birch forest   \n",
      "3                                        Adventdalen   \n",
      "4  Alberta - Western Peatland - LaBiche River,Bla...   \n",
      "\n",
      "                                      site_reference   latitude   longitude  \\\n",
      "0                        ARM-NSA-Barrow_US-A10_tower  71.323000 -156.609000   \n",
      "1                       ARM-NSA-Oliktok_US-A03_tower  70.495000 -149.886000   \n",
      "2                Abisko Stordalen birch forest_tower  68.347939   19.049769   \n",
      "3                           Adventdalen_SJ-Adv_tower  78.186000   15.923000   \n",
      "4  Alberta - Western Peatland - LaBiche River,Bla...  54.953840 -112.466980   \n",
      "\n",
      "  flux_method country  land_cover_eco  land_cover_plot    bawld_class  year  \\\n",
      "0          EC     USA           153.0            153.0     Wet Tundra  2000   \n",
      "1          EC     USA           153.0            153.0     Wet Tundra  2000   \n",
      "2          EC  Sweden            60.0             60.0  Boreal Forest  2000   \n",
      "3          EC  Norway           180.0            180.0     Wet Tundra  2000   \n",
      "4          EC  Canada           160.0            160.0            Fen  2000   \n",
      "\n",
      "   ...  clay_0_100cm nitrogen_0_100cm  ocd_0_100cm  phh2o_0_100cm  \\\n",
      "0  ...     22.227648        69.425669    65.170658       5.729838   \n",
      "1  ...     18.015117        78.211887    52.503460       6.471203   \n",
      "2  ...     13.238400        41.899736    23.136605       5.864295   \n",
      "3  ...     17.913802        66.421694    41.643476       6.580316   \n",
      "4  ...     19.723475        29.393525    13.246189       6.252252   \n",
      "\n",
      "   sand_0_100cm  silt_0_100cm  soc_0_100cm  land_cover  co2_cont  ALT  \n",
      "0     42.321892     35.450215   146.161786           4    376.89  0.1  \n",
      "1     47.787538     34.195582   120.345667           3    376.89  0.1  \n",
      "2     57.190494     29.567801    64.353214           1    376.89  NaN  \n",
      "3     45.149179     36.933076   110.023750           3    376.89  0.4  \n",
      "4     50.121325     30.162230    35.182187           4    376.89  NaN  \n",
      "\n",
      "[5 rows x 56 columns]\n",
      "\n",
      "Final DataFrame columns:\n",
      "Index(['site_name', 'site_reference', 'latitude', 'longitude', 'flux_method',\n",
      "       'country', 'land_cover_eco', 'land_cover_plot', 'bawld_class', 'year',\n",
      "       'month', 'siteID', 'NDVI', 'EVI', 'NDWI', 'aet', 'def', 'pdsi', 'pet',\n",
      "       'pr', 'ro', 'soil', 'srad', 'swe', 'tmmn', 'tmmx', 'vap', 'vpd', 'vs',\n",
      "       'lai', 'fpar', 'Percent_NonTree_Vegetation', 'Percent_NonVegetated',\n",
      "       'Percent_Tree_Cover', 'nee', 'gpp', 'reco', 'ch4_flux_total', 'Flux',\n",
      "       'sur_refl_b01', 'sur_refl_b02', 'sur_refl_b03', 'sur_refl_b07',\n",
      "       'bdod_0_100cm', 'cec_0_100cm', 'cfvo_0_100cm', 'clay_0_100cm',\n",
      "       'nitrogen_0_100cm', 'ocd_0_100cm', 'phh2o_0_100cm', 'sand_0_100cm',\n",
      "       'silt_0_100cm', 'soc_0_100cm', 'land_cover', 'co2_cont', 'ALT'],\n",
      "      dtype='object')\n",
      "\n",
      "Data type of 'land_cover' column: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Load all data sources ---\n",
    "input_data = pd.read_csv(\"/explore/nobackup/people/spotter5/anna_v/v2/v2_model_training_data_16daymodis.csv\")\n",
    "input_data2 = pd.read_csv(\"/explore/nobackup/people/spotter5/anna_v/v2/v2_model_training_data_v3.csv\")\n",
    "soil = pd.read_csv(\"/explore/nobackup/people/spotter5/anna_v/v2/integrated_soil_data_1km_v2_sites.csv\")\n",
    "landcover = pd.read_csv(\"/explore/nobackup/people/spotter5/anna_v/v2/extracted_landcover_values.csv\")\n",
    "cont = pd.read_csv(\"/explore/nobackup/people/spotter5/anna_v/v2/co2_cont.csv\")\n",
    "alt = pd.read_csv(\"/explore/nobackup/people/spotter5/anna_v/v2/ALT_by_site.csv\")\n",
    "\n",
    "# --- Initial Data Cleaning ---\n",
    "input_data = input_data[input_data['flux_method'] == 'EC']\n",
    "input_data = input_data.dropna(subset=['site_reference'])\n",
    "soil = soil.dropna(subset=['site_refer'])\n",
    "landcover = landcover.dropna(subset=['site_refer'])\n",
    "\n",
    "input_data = input_data.drop_duplicates(subset=['site_reference', 'year', 'month'])\n",
    "soil = soil.drop_duplicates(subset=['site_refer'])\n",
    "landcover = landcover.drop_duplicates(subset=['site_refer'])\n",
    "\n",
    "print(f\"Initial shape: {input_data.shape}\")\n",
    "\n",
    "# --- START: EDITED SECTION ---\n",
    "# This section replaces the surface reflectance bands in input_data with those from input_data2\n",
    "\n",
    "# 1. Define the reflectance columns to be replaced and the keys for merging\n",
    "reflectance_cols = ['sur_refl_b01', 'sur_refl_b02', 'sur_refl_b03', 'sur_refl_b07']\n",
    "merge_keys = ['site_reference', 'year', 'month']\n",
    "\n",
    "# 2. Create a small DataFrame from input_data2 with only the keys and the desired reflectance columns\n",
    "reflectance_to_merge = input_data2[merge_keys + reflectance_cols].copy()\n",
    "reflectance_to_merge = reflectance_to_merge.drop_duplicates(subset=merge_keys)\n",
    "\n",
    "# 3. Drop the old reflectance columns from the main dataframe to avoid conflicts\n",
    "# input_data = input_data.drop(columns=reflectance_cols)\n",
    "\n",
    "# 4. Merge the new reflectance values into the main dataframe\n",
    "input_data = input_data.merge(reflectance_to_merge, on=merge_keys, how='left')\n",
    "\n",
    "print(f\"After replacing reflectance bands: {input_data.shape}\")\n",
    "# --- END: EDITED SECTION ---\n",
    "\n",
    "\n",
    "# --- Prepare and Merge Soil Data ---\n",
    "soil_filtered = soil.filter(regex='100cm$').copy()\n",
    "soil_filtered[\"site_reference\"] = soil[\"site_refer\"]\n",
    "input_data = input_data.merge(soil_filtered, on=\"site_reference\", how=\"left\")\n",
    "\n",
    "print(f\"After soil merge: {input_data.shape}\")\n",
    "\n",
    "# --- Prepare and Merge Land Cover Data ---\n",
    "landcover = landcover.rename(columns={'site_refer': 'site_reference'})\n",
    "landcover = landcover[['site_reference', 'land_cover']]\n",
    "input_data = input_data.merge(landcover, on=\"site_reference\", how=\"left\")\n",
    "\n",
    "print(f\"After landcover merge: {input_data.shape}\")\n",
    "\n",
    "# --- Prepare and Merge CO2 Data ---\n",
    "co2_to_merge = cont[['year', 'month', 'value']].copy()\n",
    "co2_to_merge = co2_to_merge.rename(columns={'value': 'co2_cont'})\n",
    "co2_to_merge = co2_to_merge.drop_duplicates(subset=['year', 'month'])\n",
    "input_data = input_data.merge(co2_to_merge, on=['year', 'month'], how='left')\n",
    "\n",
    "print(f\"After CO2 merge: {input_data.shape}\")\n",
    "\n",
    "# --- Prepare and Merge ALT Data ---\n",
    "alt_to_merge = alt[['site_reference', 'year', 'ALT']].copy()\n",
    "alt_to_merge = alt_to_merge.drop_duplicates(subset=['site_reference', 'year'])\n",
    "input_data = input_data.merge(alt_to_merge, on=['site_reference', 'year'], how='left')\n",
    "\n",
    "print(f\"After ALT merge: {input_data.shape}\")\n",
    "\n",
    "# --- Final Data Type Conversion for Land Cover ---\n",
    "# Fill any missing values (NaN) in 'land_cover' with -9999\n",
    "input_data['land_cover'] = input_data['land_cover'].fillna(-9999)\n",
    "\n",
    "# Convert the 'land_cover' column to integer type\n",
    "input_data['land_cover'] = input_data['land_cover'].astype(int)\n",
    "\n",
    "# --- Save Final Combined Data ---\n",
    "# Note: The output filename includes 'mod16', you may want to change this to reflect the new data source\n",
    "output_path_final = \"/explore/nobackup/people/spotter5/anna_v/v2/v2_model_training_final_mod16.csv\"\n",
    "input_data.to_csv(output_path_final, index=False)\n",
    "\n",
    "print(f\"\\nSuccessfully merged all data and saved to: {output_path_final}\")\n",
    "print(\"Final DataFrame head:\")\n",
    "print(input_data.head())\n",
    "print(\"\\nFinal DataFrame columns:\")\n",
    "print(input_data.columns)\n",
    "print(f\"\\nData type of 'land_cover' column: {input_data['land_cover'].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01340668-64d9-4c10-abe8-e2348e69d927",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'set' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)\n\u001b[1;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mland_cover\u001b[39m\u001b[38;5;124m'\u001b[39m, axis \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mland_cover_eco\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mland_cover\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mland_cover\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mland_cover\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m      9\u001b[0m df\n",
      "File \u001b[0;32m~/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/pandas/core/frame.py:5573\u001b[0m, in \u001b[0;36mDataFrame.rename\u001b[0;34m(self, mapper, index, columns, axis, copy, inplace, level, errors)\u001b[0m\n\u001b[1;32m   5454\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrename\u001b[39m(\n\u001b[1;32m   5455\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5456\u001b[0m     mapper: Renamer \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5464\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5465\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5466\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5467\u001b[0m \u001b[38;5;124;03m    Alter axes labels.\u001b[39;00m\n\u001b[1;32m   5468\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5571\u001b[0m \u001b[38;5;124;03m    4  3  6\u001b[39;00m\n\u001b[1;32m   5572\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5573\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rename\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5574\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5575\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5576\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5577\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5579\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5580\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5581\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5582\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/pandas/core/generic.py:1104\u001b[0m, in \u001b[0;36mNDFrame._rename\u001b[0;34m(self, mapper, index, columns, axis, copy, inplace, level, errors)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         missing_labels \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1098\u001b[0m             label\n\u001b[1;32m   1099\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m index, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(replacements)\n\u001b[1;32m   1100\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m indexer[index] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1101\u001b[0m         ]\n\u001b[1;32m   1102\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_labels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1104\u001b[0m new_index \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1105\u001b[0m result\u001b[38;5;241m.\u001b[39m_set_axis_nocheck(new_index, axis\u001b[38;5;241m=\u001b[39maxis_no, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1106\u001b[0m result\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[0;32m~/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/pandas/core/indexes/base.py:6416\u001b[0m, in \u001b[0;36mIndex._transform_index\u001b[0;34m(self, func, level)\u001b[0m\n\u001b[1;32m   6414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_tuples(items, names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames)\n\u001b[1;32m   6415\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 6416\u001b[0m     items \u001b[38;5;241m=\u001b[39m [func(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m]\n\u001b[1;32m   6417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Index(items, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, tupleize_cols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/pandas/core/indexes/base.py:6416\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   6414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_tuples(items, names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames)\n\u001b[1;32m   6415\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 6416\u001b[0m     items \u001b[38;5;241m=\u001b[39m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m]\n\u001b[1;32m   6417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Index(items, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, tupleize_cols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'set' object is not callable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"/explore/nobackup/people/spotter5/anna_v/v2/v2_model_training_final.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df = df.drop('land_cover', axis =1)\n",
    "df = df.rename(columns = {'land_cover_eco', 'land_cover'})\n",
    "df['land_cover'] = df['land_cover'].astype(str)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "514ac0ea-321a-4fd4-9609-b532c6e679b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['site_name', 'site_reference', 'latitude', 'longitude', 'flux_method',\n",
       "       'country', 'land_cover_eco', 'land_cover_plot', 'bawld_class', 'year',\n",
       "       'month', 'siteID', 'EVI', 'NDVI', 'SummaryQA', 'sur_refl_b01',\n",
       "       'sur_refl_b02', 'sur_refl_b03', 'sur_refl_b07', 'NDWI', 'aet', 'def',\n",
       "       'pdsi', 'pet', 'pr', 'ro', 'soil', 'srad', 'swe', 'tmmn', 'tmmx', 'vap',\n",
       "       'vpd', 'vs', 'lai', 'fpar', 'Percent_NonTree_Vegetation',\n",
       "       'Percent_NonVegetated', 'Percent_Tree_Cover', 'snow_cover',\n",
       "       'snow_depth', 'NDSI_snow_cover', 'nee', 'gpp', 'reco', 'ch4_flux_total',\n",
       "       'expert_flag_co2', 'expert_flag_ch4', 'expert_flag_gpp',\n",
       "       'expert_flag_reco', 'Flux', 'bdod_0_100cm', 'cec_0_100cm',\n",
       "       'cfvo_0_100cm', 'clay_0_100cm', 'nitrogen_0_100cm', 'ocd_0_100cm',\n",
       "       'phh2o_0_100cm', 'sand_0_100cm', 'silt_0_100cm', 'soc_0_100cm',\n",
       "       'co2_cont', 'ALT', 'sm_surface', 'sm_rootzone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219c8d75-d784-4bac-865e-7d2ee1fef1be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-xgboost_gpu]",
   "language": "python",
   "name": "conda-env-.conda-xgboost_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

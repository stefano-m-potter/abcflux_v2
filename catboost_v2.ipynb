{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4227ab6b-d92f-4ed8-9fa2-65d023d9e955",
   "metadata": {},
   "source": [
    "LOOSO gpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cad19d56-61fb-46b9-963d-c508e454c63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_3497478/263405568.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = X[col].astype('category')\n",
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_3497478/263405568.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = X[col].astype('category')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing site: Fyodorovskoye_RU-Fyo_tower...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Suppress warnings\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore::FutureWarning'\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# 1. Load your dataset\n",
    "file_path = \"/explore/nobackup/people/spotter5/anna_v/v2/v2_model_training_final.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "# df = df[df['land_cover'] != -9999.0]\n",
    "# df['land_cover'] = df['land_cover'].astype(str)\n",
    "df['land_cover'] = df['land_cover'].astype(int)\n",
    "df['month'] = df['month'].astype(int)\n",
    "\n",
    "df = df[df['flux_method'] == 'EC']\n",
    "\n",
    "# 2. Create tmean_C and date\n",
    "df['tmean_C'] = df[['tmmn', 'tmmx']].mean(axis=1)\n",
    "df['date'] = pd.to_datetime(df[['year', 'month']].assign(day=1))\n",
    "\n",
    "# 3. Define predictors and target\n",
    "# Added 'land_cover' and 'month' to the list of predictors for CatBoost\n",
    "feature_cols = [\n",
    "    'EVI', 'NDVI', 'sur_refl_b01', 'sur_refl_b02', 'sur_refl_b03', \n",
    "    'sur_refl_b07', 'NDWI', 'pdsi', 'srad', 'tmean_C', 'vap', 'vs',\n",
    "    'bdod_0_100cm', 'cec_0_100cm', 'cfvo_0_100cm', 'clay_0_100cm',\n",
    "    'nitrogen_0_100cm', 'ocd_0_100cm', 'phh2o_0_100cm', 'sand_0_100cm',\n",
    "    'silt_0_100cm', 'soc_0_100cm', 'co2_cont', 'ALT',\n",
    "    'land_cover', 'month', \n",
    "    'lai', 'fpar', 'Percent_NonTree_Vegetation',\n",
    "    'Percent_NonVegetated', 'Percent_Tree_Cover'\n",
    "]\n",
    "\n",
    "target_col = 'gpp'\n",
    "categorical_features = ['land_cover', 'month']\n",
    "\n",
    "# Drop rows only if the target variable or site_reference is missing.\n",
    "# CatBoost will handle missing values in the numerical predictor variables.\n",
    "df = df.dropna(subset=['site_reference', target_col])\n",
    "\n",
    "# Define output path for CSVs and create it\n",
    "out_path = os.path.join(\"/explore/nobackup/people/spotter5/anna_v/v2/loocv\", target_col)\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "# Define a separate output path for figures and create it\n",
    "figures_path = os.path.join(out_path, \"figures\")\n",
    "os.makedirs(figures_path, exist_ok=True)\n",
    "\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "# No one-hot encoding is needed for CatBoost\n",
    "X = df[feature_cols]\n",
    "y = df[target_col]\n",
    "sites = df[\"site_reference\"].unique()\n",
    "\n",
    "# Convert categorical features to 'category' dtype for CatBoost\n",
    "for col in categorical_features:\n",
    "    X[col] = X[col].astype('category')\n",
    "\n",
    "results = []\n",
    "all_preds_df_list = []\n",
    "\n",
    "# Leave-One-Site-Out CV\n",
    "for test_site in sites:\n",
    "    print(f\"Processing site: {test_site}...\")\n",
    "    train_idx = df[\"site_reference\"] != test_site\n",
    "    test_idx = df[\"site_reference\"] == test_site\n",
    "\n",
    "    if test_idx.sum() < 1:\n",
    "        continue\n",
    "\n",
    "    X_train, y_train = X.loc[train_idx], y.loc[train_idx]\n",
    "    X_test, y_test = X.loc[test_idx], y.loc[test_idx]\n",
    "    dates_test = df.loc[test_idx, \"date\"]\n",
    "\n",
    "    # Initialize and train the CatBoost model\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=1200, #best is 700 and 3, score of 0.74\n",
    "        learning_rate=0.01,\n",
    "        depth=8,\n",
    "        subsample=0.7,\n",
    "        random_state=42,\n",
    "        l2_leaf_reg=0.1,\n",
    "        cat_features=categorical_features,\n",
    "        verbose=0, # Suppress verbose output\n",
    "        allow_writing_files=False\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    site_df = pd.DataFrame({\n",
    "        \"Site\": test_site,\n",
    "        \"Date\": dates_test.values,\n",
    "        \"Observed\": y_test.values,\n",
    "        \"Predicted\": y_pred\n",
    "    })\n",
    "    all_preds_df_list.append(site_df)\n",
    "\n",
    "    # Metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    results.append({\n",
    "        \"Site\": test_site,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"R2\": r2\n",
    "    })\n",
    "\n",
    "# Combine results\n",
    "results_df = pd.DataFrame(results)\n",
    "all_preds_df = pd.concat(all_preds_df_list, ignore_index=True)\n",
    "\n",
    "# Save to disk with '_cat' suffix\n",
    "results_csv_path = os.path.join(out_path, f'catboost_results_{target_col}_cat.csv')\n",
    "predictions_csv_path = os.path.join(out_path, f'catboost_predictions_{target_col}_cat.csv')\n",
    "results_df.to_csv(results_csv_path, index=False)\n",
    "all_preds_df.to_csv(predictions_csv_path, index=False)\n",
    "print(f\"\\nResults saved to: {results_csv_path}\")\n",
    "print(f\"Predictions saved to: {predictions_csv_path}\")\n",
    "\n",
    "\n",
    "# Pooled metrics\n",
    "rmse_all = np.sqrt(mean_squared_error(all_preds_df[\"Observed\"], all_preds_df[\"Predicted\"]))\n",
    "r2_all = r2_score(all_preds_df[\"Observed\"], all_preds_df[\"Predicted\"])\n",
    "mae_all = mean_absolute_error(all_preds_df[\"Observed\"], all_preds_df[\"Predicted\"])\n",
    "\n",
    "print(\"\\n--- Site-Specific Results ---\")\n",
    "print(results_df)\n",
    "print(\"\\n--- Pooled Metrics ---\")\n",
    "print(f\"Pooled RMSE: {rmse_all:.4f}\")\n",
    "print(f\"Pooled MAE:  {mae_all:.4f}\")\n",
    "print(f\"Pooled R²:   {r2_all:.4f}\")\n",
    "\n",
    "# Median metrics across sites\n",
    "median_rmse = results_df[\"RMSE\"].median()\n",
    "median_mae = results_df[\"MAE\"].median()\n",
    "median_r2 = results_df[\"R2\"].median()\n",
    "\n",
    "print(\"\\n--- Median Metrics Across Sites ---\")\n",
    "print(f\"Median RMSE: {median_rmse:.4f}\")\n",
    "print(f\"Median MAE:  {median_mae:.4f}\")\n",
    "print(f\"Median R²:   {median_r2:.4f}\")\n",
    "\n",
    "# --- Plotting ---\n",
    "# Loop through each site and save a separate plot\n",
    "unique_sites = all_preds_df[\"Site\"].unique()\n",
    "if not unique_sites.any():\n",
    "    print(\"\\nNo sites to plot.\")\n",
    "else:\n",
    "    print(\"\\nGenerating and saving individual site plots...\")\n",
    "    for site in unique_sites:\n",
    "        fig, ax = plt.subplots(figsize=(12, 7))\n",
    "        \n",
    "        site_df = all_preds_df[all_preds_df[\"Site\"] == site].sort_values(\"Date\")\n",
    "        site_metrics = results_df[results_df[\"Site\"] == site].iloc[0]\n",
    "        rmse_val = round(site_metrics[\"RMSE\"], 2)\n",
    "        r2_val = round(site_metrics[\"R2\"], 2)\n",
    "        mae_val = round(site_metrics[\"MAE\"], 2)\n",
    "\n",
    "        ax.plot(site_df[\"Date\"], site_df[\"Observed\"], label=\"Observed\", marker=\"o\", linestyle='-', markersize=4)\n",
    "        ax.plot(site_df[\"Date\"], site_df[\"Predicted\"], label=\"Predicted\", marker=\"x\", linestyle='--', markersize=4)\n",
    "        ax.set_title(f\"Observed vs. Predicted {target_col} for Site: {site}\")\n",
    "        ax.set_xlabel(\"Date\")\n",
    "        ax.set_ylabel(target_col)\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "        fig.autofmt_xdate() # Auto-formats the x-axis labels for dates\n",
    "\n",
    "        # Add metrics text to the plot\n",
    "        textstr = f\"RMSE: {rmse_val}\\nMAE: {mae_val}\\nR²: {r2_val}\"\n",
    "        ax.text(\n",
    "            0.97, 0.03, textstr,\n",
    "            transform=ax.transAxes,\n",
    "            fontsize=10,\n",
    "            verticalalignment='bottom',\n",
    "            horizontalalignment='right',\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.7)\n",
    "        )\n",
    "        \n",
    "        # Define the output path for the plot\n",
    "        plot_filename = f'catboost_{target_col}_{site}_timeseries_cat.png'\n",
    "        plot_path = os.path.join(figures_path, plot_filename)\n",
    "        \n",
    "        # Save the figure\n",
    "        plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        # Close the plot to free up memory\n",
    "        plt.close(fig)\n",
    "        \n",
    "    print(f\"All site plots saved to: {figures_path}\")\n",
    "\n",
    "out_path = '/explore/nobackup/people/spotter5/anna_v/v2/models'\n",
    "os.makedirs(out_path, exist_ok = True)\n",
    "model_filename = f'{target_col}.json'\n",
    "model.save_model(os.path.join(out_path, model_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3637f83d-9182-4888-badc-fb376334fc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of 'land_cover' column: int64\n",
      "Unique values in 'land_cover': [    4     1     0     2     3 -9999]\n",
      "\n",
      "Data type of 'month' column: float64\n",
      "Unique values in 'month': [ 3.  4.  5.  6.  7.  8.  9. 10. 11. 12.  1.  2.]\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv(file_path)\n",
    "# df['land_cover'] = df['land_cover'].astype(int)\n",
    "# df['land_cover'].unique()\n",
    "\n",
    "print(f\"Data type of 'land_cover' column: {df['land_cover'].dtype}\")\n",
    "print(f\"Unique values in 'land_cover': {df['land_cover'].unique()}\")\n",
    "\n",
    "print(f\"\\nData type of 'month' column: {df['month'].dtype}\")\n",
    "print(f\"Unique values in 'month': {df['month'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e1b7024-8e71-4e96-a09c-57920c9fe7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4]\n",
       "Categories (6, int64): [-9999, 0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['land_cover'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23f0de3-8d7e-4433-a30d-cecf765984b7",
   "metadata": {},
   "source": [
    "LOOSO NEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5554b0df-b499-4082-9c61-4639b42d884c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_2730655/4044039451.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = X[col].astype('category')\n",
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_2730655/4044039451.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = X[col].astype('category')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing site: Fyodorovskoye_RU-Fyo_tower...\n",
      "Processing site: Saskatchewan - Western Boreal, Mature Aspen_CA-Oas_tower...\n",
      "Processing site: Saskatchewan - Western Boreal, Mature Jack Pine_CA-Ojp_tower...\n",
      "Processing site: Flakaliden_SE-Fla_tower...\n",
      "Processing site: Hyytiala_FI-Hyy_tower...\n",
      "Processing site: Manitoba - Northern Old Black Spruce (former BOREAS Northern Study Area)_CA-Man_tower...\n",
      "Processing site: Saskatchewan - Western Boreal, Mature Black Spruce_CA-Obs_tower...\n",
      "Processing site: Kaamanen_FI-Kaa_tower...\n",
      "Processing site: Nelegel_RU-Nel_tower...\n",
      "Processing site: Neleger Burnt Forest_RU-NeB_tower...\n",
      "Processing site: Neleger larch forest_RU-NeF_tower...\n",
      "Processing site: Zackenberg Heath_GL-ZaH_tower...\n",
      "Processing site: Central Marsh_US-Cms_tower...\n",
      "Processing site: Yakutsk Spasskaya Pad larch_RU-SkP_tower...\n",
      "Processing site: Zotino; Central Siberia_RU-Zfw 2_tower...\n",
      "Processing site: Degero_SE-Deg_tower...\n",
      "Processing site: Sodankyla_FI-Sod_tower...\n",
      "Processing site: UCI-1964 burn site_CA-NS3_tower...\n",
      "Processing site: Neleger Cutover_RU-NeC_tower...\n",
      "Processing site: Saskatchewan - Western Boreal, forest burned in 1998_CA-SF3_tower...\n",
      "Processing site: Saskatchewan - Western Boreal, forest burned in 1989_CA-SF2_tower...\n",
      "Processing site: UCI-1998 burn site_CA-NS7_tower...\n",
      "Processing site: UCI-1930 burn site_CA-NS2_tower...\n",
      "Processing site: UCI-1981 burn site_CA-NS5_tower...\n",
      "Processing site: UCI-1989 burn site_CA-NS6_tower...\n",
      "Processing site: Delta Junction deciduous broadleaf forest_US-Bn1_tower...\n",
      "Processing site: Samoylov Island_RU-Sam_tower...\n",
      "Processing site: Zotino_RU-Zot_tower...\n",
      "Processing site: UCI-1850 burn site_CA-NS1_tower...\n",
      "Processing site: Hakasia 5yr_RU-Ha2_tower...\n",
      "Processing site: Hakasia Steppe_RU-Ha1_tower...\n",
      "Processing site: UCI-1964 burn site wet_CA-NS4_tower...\n",
      "Processing site: Norunda_SE-Nor_tower...\n",
      "Processing site: Delta Junction  evergreen conifer forest_US-Bn2_tower...\n",
      "Processing site: Kherlenbayan Ulaan_MN-Kbu_tower...\n",
      "Processing site: Southern Khentei Taiga_MN-Skt_tower...\n",
      "Processing site: University of Alaska, Fairbanks_US-Uaf_tower...\n",
      "Processing site: Kytalyk, Russia_RU-Cok_tower...\n",
      "Processing site: Ontario - Groundhog River, Boreal Mixedwood Forest_CA-Gro_tower...\n",
      "Processing site: Saskatchewan - Western Boreal, forest burned in 1977_CA-SF1_tower...\n",
      "Processing site: Alberta - Western Peatland - LaBiche River,Black Spruce,Larch Fen_CA-WP1_tower...\n",
      "Processing site: Quebec - Eastern Boreal, Mature Black Spruce_CA-Qfo_tower...\n",
      "Processing site: Saskatchewan - Western Boreal, Jack Pine harvested in 1975_CA-SJ3_tower...\n",
      "Processing site: Skyttorp 2_SE-Sk2_tower...\n",
      "Processing site: HJP02 Jack Pine_CA-HJP02_tower...\n",
      "Processing site: HJP94 Jack Pine_CA-HJP94_tower...\n",
      "Processing site: Saskatchewan - Western Boreal, Jack Pine harvested in 2002_CA-SJ2_tower...\n",
      "Processing site: Hakasia 10 yr_RU-Ha3_tower...\n",
      "Processing site: Alberta - Western Peatland - Poor Fen (Sphagnum moss)_CA-WP2_tower...\n",
      "Processing site: Alberta - Western Peatland - Rich Fen  (Carex)_CA-WP3_tower...\n",
      "Processing site: HJP75 Jack Pine_CA-HJP75_tower...\n",
      "Processing site: Ivotuk_US-Ivo_tower...\n",
      "Processing site: Yakutsk Spasskaya Pad Pine_RU-Sk2_tower...\n",
      "Processing site: Atqasuk_US-Atq_tower...\n",
      "Processing site: Daring Lake_CA-DL1_tower...\n",
      "Processing site: Tura_RU-Tur_tower...\n",
      "Processing site: Kalevansuo_FI-Kns_tower...\n",
      "Processing site: Skyttorp 1_SE-Sk1_tower...\n",
      "Processing site: Siikaneva_FI-Sii_tower...\n",
      "Processing site: Barrow-BES_US-Bes_tower...\n",
      "Processing site: Faejemyr_SE-Faj_tower...\n",
      "Processing site: Knottasen_SE-Kno_tower...\n",
      "Processing site: Salmisuo_FI-Salm_tower...\n",
      "Processing site: Lompolojankka_FI-Lom_tower...\n",
      "Processing site: Churchill Fen Site 1_CA-CF1_tower...\n",
      "Processing site: Imnavait Creek Watershed Tussock Tundra_US-ICt_tower...\n",
      "Processing site: Imnavait Creek Watershed Heath Tundra_US-ICh_tower...\n",
      "Processing site: Imnavait Creek Watershed Wet Sedge Tundra_US-ICs_tower...\n",
      "Processing site: Quebec - 1975 Harvested Black Spruce_CA-Qc2_tower...\n",
      "Processing site: Eight Mile Lake_US-EML_tower...\n",
      "Processing site: Lac Le Caron peatland, an ombrotrophic bog_CA-LLC_tower...\n",
      "Processing site: Anaktuvuk River Moderate Burn_US-An2_tower...\n",
      "Processing site: Anaktuvuk River Severe Burn_US-An1_tower...\n",
      "Processing site: Anaktuvuk River Unburned_US-An3_tower...\n",
      "Processing site: Cape Bounty_CA-CB_tower...\n",
      "Processing site: Nuuk Fen_GL-NuF_tower...\n",
      "Processing site: Rylekaerene_tower...\n",
      "Processing site: Seida_RU-Vrk_tower...\n",
      "Processing site: Zackenberg Fen_GL-ZaF_tower...\n",
      "Processing site: Andoya_NO-And_tower...\n",
      "Processing site: Bayelva, Spitsbergen_SJ-Blv_tower...\n",
      "Processing site: Iqaluit_CA-Iqa_tower...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/sklearn/metrics/_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing site: Pond Inlet_CA-Pin_tower...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/sklearn/metrics/_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing site: Poker Flat Research Range: Succession from fire scar to deciduous forest_US-Rpf_tower...\n",
      "Processing site: Lake Hazen, Ellesmere Island_CA-LHazen1-semidesert_tower...\n",
      "Processing site: Samoylov Island_RU-Sam (open)_tower...\n",
      "Processing site: Lettosuo_FI-Let_tower...\n",
      "Processing site: Udleg practice forest_MN-Udg_tower...\n",
      "Processing site: Daring Lake_CA-DL3_tower...\n",
      "Processing site: Elgeeii forest station_RU-Ege_tower...\n",
      "Processing site: Bonanza Creek Black Spruce_US-BZS_tower...\n",
      "Processing site: Daring Lake_CA-DL4_tower...\n",
      "Processing site: Tiksi_RU-Tks_tower...\n",
      "Processing site: Samoylov Island_RU-Sam (closed)_tower...\n",
      "Processing site: Attawapiskat River Fen_CA-ARF_tower...\n",
      "Processing site: Bonanza Creek Thermokarst Bog_US-BZB_tower...\n",
      "Processing site: Poker Flat Research Range Black Spruce Forest_US-Prr_tower...\n",
      "Processing site: Attawapiskat River Bog_CA-ARB_tower...\n",
      "Processing site: Bonanza Creek Rich Fen_US-BZF_tower...\n",
      "Processing site: Cascaden Ridge Fire Scar_US-Fcr_tower...\n",
      "Processing site: Siikaneva2_FI-Si2_tower...\n",
      "Processing site: Cherskii ecotone_RU-Eusk_cher1_tower...\n",
      "Processing site: Kenttarova_FI-Ken_tower...\n",
      "Processing site: Sammaltunturi fell_FI-SamFell_tower...\n",
      "Processing site: Varrio_FI-Var_tower...\n",
      "Processing site: ARM-NSA-Barrow_US-A10_tower...\n",
      "Processing site: Adventdalen_SJ-Adv_tower...\n",
      "Processing site: Lake Hazen, Ellesmere Island_CA-LHazen2-meadow wetland_tower...\n",
      "Processing site: Stordalen Fen_SE-St1_tower...\n",
      "Processing site: Tervalamminsuo_Dry_tower...\n",
      "Processing site: Tervalamminsuo_Wet_tower...\n",
      "Processing site: NGEE Arctic Barrow_US-NGB_tower...\n",
      "Processing site: Cherskii disturbed forest_RU-Eusk_cher2_tower...\n",
      "Processing site: Disko_GL-Dsk_tower...\n",
      "Processing site: Havikpak Creek_CA-HPC_tower...\n",
      "Processing site: Scotty Creek Landscape_CA-SCC_tower...\n",
      "Processing site: ZOTTO Bog_RU-Zo1_tower...\n",
      "Processing site: ZOTTO Forest_RU-Zo2_tower...\n",
      "Processing site: Trail Valley Creek_CA-TVC_tower...\n",
      "Processing site: Cherskii reference_RU-Ch2_tower...\n",
      "Processing site: Flux Observations of Carbon from an Airborne Laboratory (FOCAL) Campaign Site 1_US-Fo1_tower...\n",
      "Processing site: Barrow-CMDL_US-Brw_tower...\n",
      "Processing site: Svartberget_SE-Svb_tower...\n",
      "Processing site: Scotty Creek Bog_CA-SCB_tower...\n",
      "Processing site: Stordalen Palsa Bog_SE-Sto_tower...\n",
      "Processing site: Barrow-BEO_US-Beo_tower...\n",
      "Processing site: Council, Alaska_US-KOC_tower...\n",
      "Processing site: Rosinedal-3_SE-Ros_tower...\n",
      "Processing site: ARM-NSA-Oliktok_US-A03_tower...\n",
      "Processing site: Hyltemossa_SE-Htm_tower...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Suppress warnings\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore::FutureWarning'\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# 1. Load your dataset\n",
    "file_path = \"/explore/nobackup/people/spotter5/anna_v/v2/v2_model_training_final.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df = df[df['flux_method'] == 'EC']\n",
    "\n",
    "# 2. Create tmean_C and date\n",
    "df['tmean_C'] = df[['tmmn', 'tmmx']].mean(axis=1)\n",
    "df['date'] = pd.to_datetime(df[['year', 'month']].assign(day=1))\n",
    "\n",
    "# 3. Define predictors and target\n",
    "# Added 'land_cover' and 'month' to the list of predictors for CatBoost\n",
    "feature_cols = [\n",
    "    'EVI', 'NDVI', 'sur_refl_b01', 'sur_refl_b02', 'sur_refl_b03', \n",
    "    'sur_refl_b07', 'NDWI', 'pdsi', 'srad', 'tmean_C', 'vap', 'vs',\n",
    "    'bdod_0_100cm', 'cec_0_100cm', 'cfvo_0_100cm', 'clay_0_100cm',\n",
    "    'nitrogen_0_100cm', 'ocd_0_100cm', 'phh2o_0_100cm', 'sand_0_100cm',\n",
    "    'silt_0_100cm', 'soc_0_100cm', 'co2_cont', 'ALT',\n",
    "    'land_cover', 'month', \n",
    "    'lai', 'fpar', 'Percent_NonTree_Vegetation',\n",
    "    'Percent_NonVegetated', 'Percent_Tree_Cover'\n",
    "]\n",
    "target_col = 'nee'\n",
    "categorical_features = ['land_cover', 'month']\n",
    "\n",
    "# Drop rows only if the target variable or site_reference is missing.\n",
    "# CatBoost will handle missing values in the numerical predictor variables.\n",
    "df = df.dropna(subset=['site_reference', target_col])\n",
    "\n",
    "# Define output path for CSVs and create it\n",
    "out_path = os.path.join(\"/explore/nobackup/people/spotter5/anna_v/v2/loocv\", target_col)\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "# Define a separate output path for figures and create it\n",
    "figures_path = os.path.join(out_path, \"figures\")\n",
    "os.makedirs(figures_path, exist_ok=True)\n",
    "\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "# No one-hot encoding is needed for CatBoost\n",
    "X = df[feature_cols]\n",
    "y = df[target_col]\n",
    "sites = df[\"site_reference\"].unique()\n",
    "\n",
    "# Convert categorical features to 'category' dtype for CatBoost\n",
    "for col in categorical_features:\n",
    "    X[col] = X[col].astype('category')\n",
    "\n",
    "results = []\n",
    "all_preds_df_list = []\n",
    "\n",
    "# Leave-One-Site-Out CV\n",
    "for test_site in sites:\n",
    "    print(f\"Processing site: {test_site}...\")\n",
    "    train_idx = df[\"site_reference\"] != test_site\n",
    "    test_idx = df[\"site_reference\"] == test_site\n",
    "\n",
    "    if test_idx.sum() < 1:\n",
    "        continue\n",
    "\n",
    "    X_train, y_train = X.loc[train_idx], y.loc[train_idx]\n",
    "    X_test, y_test = X.loc[test_idx], y.loc[test_idx]\n",
    "    dates_test = df.loc[test_idx, \"date\"]\n",
    "\n",
    "    # Initialize and train the CatBoost model\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=1200, #1200, 8 is best\n",
    "        learning_rate=0.01,\n",
    "        depth=8,\n",
    "        # subsample=0.7,\n",
    "        l2_leaf_reg=0.1,\n",
    "        random_state=42,\n",
    "        cat_features=categorical_features,\n",
    "        verbose=0, # Suppress verbose output\n",
    "        allow_writing_files=False\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    site_df = pd.DataFrame({\n",
    "        \"Site\": test_site,\n",
    "        \"Date\": dates_test.values,\n",
    "        \"Observed\": y_test.values,\n",
    "        \"Predicted\": y_pred\n",
    "    })\n",
    "    all_preds_df_list.append(site_df)\n",
    "\n",
    "    # Metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    results.append({\n",
    "        \"Site\": test_site,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"R2\": r2\n",
    "    })\n",
    "\n",
    "# Combine results\n",
    "results_df = pd.DataFrame(results)\n",
    "all_preds_df = pd.concat(all_preds_df_list, ignore_index=True)\n",
    "\n",
    "# Save to disk with '_cat' suffix\n",
    "results_csv_path = os.path.join(out_path, f'catboost_results_{target_col}_cat.csv')\n",
    "predictions_csv_path = os.path.join(out_path, f'catboost_predictions_{target_col}_cat.csv')\n",
    "results_df.to_csv(results_csv_path, index=False)\n",
    "all_preds_df.to_csv(predictions_csv_path, index=False)\n",
    "print(f\"\\nResults saved to: {results_csv_path}\")\n",
    "print(f\"Predictions saved to: {predictions_csv_path}\")\n",
    "\n",
    "\n",
    "# Pooled metrics\n",
    "rmse_all = np.sqrt(mean_squared_error(all_preds_df[\"Observed\"], all_preds_df[\"Predicted\"]))\n",
    "r2_all = r2_score(all_preds_df[\"Observed\"], all_preds_df[\"Predicted\"])\n",
    "mae_all = mean_absolute_error(all_preds_df[\"Observed\"], all_preds_df[\"Predicted\"])\n",
    "\n",
    "print(\"\\n--- Site-Specific Results ---\")\n",
    "print(results_df)\n",
    "print(\"\\n--- Pooled Metrics ---\")\n",
    "print(f\"Pooled RMSE: {rmse_all:.4f}\")\n",
    "print(f\"Pooled MAE:  {mae_all:.4f}\")\n",
    "print(f\"Pooled R²:   {r2_all:.4f}\")\n",
    "\n",
    "# Median metrics across sites\n",
    "median_rmse = results_df[\"RMSE\"].median()\n",
    "median_mae = results_df[\"MAE\"].median()\n",
    "median_r2 = results_df[\"R2\"].median()\n",
    "\n",
    "print(\"\\n--- Median Metrics Across Sites ---\")\n",
    "print(f\"Median RMSE: {median_rmse:.4f}\")\n",
    "print(f\"Median MAE:  {median_mae:.4f}\")\n",
    "print(f\"Median R²:   {median_r2:.4f}\")\n",
    "\n",
    "# --- Plotting ---\n",
    "# Loop through each site and save a separate plot\n",
    "unique_sites = all_preds_df[\"Site\"].unique()\n",
    "if not unique_sites.any():\n",
    "    print(\"\\nNo sites to plot.\")\n",
    "else:\n",
    "    print(\"\\nGenerating and saving individual site plots...\")\n",
    "    for site in unique_sites:\n",
    "        fig, ax = plt.subplots(figsize=(12, 7))\n",
    "        \n",
    "        site_df = all_preds_df[all_preds_df[\"Site\"] == site].sort_values(\"Date\")\n",
    "        site_metrics = results_df[results_df[\"Site\"] == site].iloc[0]\n",
    "        rmse_val = round(site_metrics[\"RMSE\"], 2)\n",
    "        r2_val = round(site_metrics[\"R2\"], 2)\n",
    "        mae_val = round(site_metrics[\"MAE\"], 2)\n",
    "\n",
    "        ax.plot(site_df[\"Date\"], site_df[\"Observed\"], label=\"Observed\", marker=\"o\", linestyle='-', markersize=4)\n",
    "        ax.plot(site_df[\"Date\"], site_df[\"Predicted\"], label=\"Predicted\", marker=\"x\", linestyle='--', markersize=4)\n",
    "        ax.set_title(f\"Observed vs. Predicted {target_col} for Site: {site}\")\n",
    "        ax.set_xlabel(\"Date\")\n",
    "        ax.set_ylabel(target_col)\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "        fig.autofmt_xdate() # Auto-formats the x-axis labels for dates\n",
    "\n",
    "        # Add metrics text to the plot\n",
    "        textstr = f\"RMSE: {rmse_val}\\nMAE: {mae_val}\\nR²: {r2_val}\"\n",
    "        ax.text(\n",
    "            0.97, 0.03, textstr,\n",
    "            transform=ax.transAxes,\n",
    "            fontsize=10,\n",
    "            verticalalignment='bottom',\n",
    "            horizontalalignment='right',\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.7)\n",
    "        )\n",
    "        \n",
    "        # Define the output path for the plot\n",
    "        plot_filename = f'catboost_{target_col}_{site}_timeseries_cat.png'\n",
    "        plot_path = os.path.join(figures_path, plot_filename)\n",
    "        \n",
    "        # Save the figure\n",
    "        plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        # Close the plot to free up memory\n",
    "        plt.close(fig)\n",
    "        \n",
    "    print(f\"All site plots saved to: {figures_path}\")\n",
    "\n",
    "out_path = '/explore/nobackup/people/spotter5/anna_v/v2/models'\n",
    "os.makedirs(out_path, exist_ok = True)\n",
    "model_filename = f'{target_col}.json'\n",
    "model.save_model(os.path.join(out_path, model_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308e5685-fbcc-410c-a4bf-a712f7cabacb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "LOOSO RECO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ca456b2-b006-473d-a547-f78119bdc854",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_2730655/287600856.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = X[col].astype('category')\n",
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_2730655/287600856.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = X[col].astype('category')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing site: Fyodorovskoye_RU-Fyo_tower...\n",
      "Processing site: Saskatchewan - Western Boreal, Mature Aspen_CA-Oas_tower...\n",
      "Processing site: Saskatchewan - Western Boreal, Mature Jack Pine_CA-Ojp_tower...\n",
      "Processing site: Hyytiala_FI-Hyy_tower...\n",
      "Processing site: Manitoba - Northern Old Black Spruce (former BOREAS Northern Study Area)_CA-Man_tower...\n",
      "Processing site: Saskatchewan - Western Boreal, Mature Black Spruce_CA-Obs_tower...\n",
      "Processing site: Kaamanen_FI-Kaa_tower...\n",
      "Processing site: Neleger Burnt Forest_RU-NeB_tower...\n",
      "Processing site: Neleger larch forest_RU-NeF_tower...\n",
      "Processing site: Nelegel_RU-Nel_tower...\n",
      "Processing site: Zackenberg Heath_GL-ZaH_tower...\n",
      "Processing site: Central Marsh_US-Cms_tower...\n",
      "Processing site: Zotino; Central Siberia_RU-Zfw 2_tower...\n",
      "Processing site: Degero_SE-Deg_tower...\n",
      "Processing site: Flakaliden_SE-Fla_tower...\n",
      "Processing site: Neleger Cutover_RU-NeC_tower...\n",
      "Processing site: Sodankyla_FI-Sod_tower...\n",
      "Processing site: UCI-1964 burn site_CA-NS3_tower...\n",
      "Processing site: Saskatchewan - Western Boreal, forest burned in 1989_CA-SF2_tower...\n",
      "Processing site: UCI-1930 burn site_CA-NS2_tower...\n",
      "Processing site: UCI-1981 burn site_CA-NS5_tower...\n",
      "Processing site: UCI-1989 burn site_CA-NS6_tower...\n",
      "Processing site: Samoylov Island_RU-Sam_tower...\n",
      "Processing site: UCI-1998 burn site_CA-NS7_tower...\n",
      "Processing site: Zotino_RU-Zot_tower...\n",
      "Processing site: UCI-1850 burn site_CA-NS1_tower...\n",
      "Processing site: Hakasia Steppe_RU-Ha1_tower...\n",
      "Processing site: Saskatchewan - Western Boreal, forest burned in 1998_CA-SF3_tower...\n",
      "Processing site: UCI-1964 burn site wet_CA-NS4_tower...\n",
      "Processing site: Norunda_SE-Nor_tower...\n",
      "Processing site: Kherlenbayan Ulaan_MN-Kbu_tower...\n",
      "Processing site: Southern Khentei Taiga_MN-Skt_tower...\n",
      "Processing site: University of Alaska, Fairbanks_US-Uaf_tower...\n",
      "Processing site: Atqasuk_US-Atq_tower...\n",
      "Processing site: Kytalyk, Russia_RU-Cok_tower...\n",
      "Processing site: Ontario - Groundhog River, Boreal Mixedwood Forest_CA-Gro_tower...\n",
      "Processing site: Saskatchewan - Western Boreal, forest burned in 1977_CA-SF1_tower...\n",
      "Processing site: Alberta - Western Peatland - LaBiche River,Black Spruce,Larch Fen_CA-WP1_tower...\n",
      "Processing site: Quebec - Eastern Boreal, Mature Black Spruce_CA-Qfo_tower...\n",
      "Processing site: Saskatchewan - Western Boreal, Jack Pine harvested in 1975_CA-SJ3_tower...\n",
      "Processing site: Skyttorp 2_SE-Sk2_tower...\n",
      "Processing site: HJP02 Jack Pine_CA-HJP02_tower...\n",
      "Processing site: HJP94 Jack Pine_CA-HJP94_tower...\n",
      "Processing site: Saskatchewan - Western Boreal, Jack Pine harvested in 2002_CA-SJ2_tower...\n",
      "Processing site: Yakutsk Spasskaya Pad Pine_RU-Sk2_tower...\n",
      "Processing site: Yakutsk Spasskaya Pad larch_RU-SkP_tower...\n",
      "Processing site: Alberta - Western Peatland - Poor Fen (Sphagnum moss)_CA-WP2_tower...\n",
      "Processing site: Alberta - Western Peatland - Rich Fen  (Carex)_CA-WP3_tower...\n",
      "Processing site: HJP75 Jack Pine_CA-HJP75_tower...\n",
      "Processing site: Ivotuk_US-Ivo_tower...\n",
      "Processing site: Tura_RU-Tur_tower...\n",
      "Processing site: Daring Lake_CA-DL1_tower...\n",
      "Processing site: Kalevansuo_FI-Kns_tower...\n",
      "Processing site: Skyttorp 1_SE-Sk1_tower...\n",
      "Processing site: Salmisuo_FI-Salm_tower...\n",
      "Processing site: Lompolojankka_FI-Lom_tower...\n",
      "Processing site: Churchill Fen Site 1_CA-CF1_tower...\n",
      "Processing site: Imnavait Creek Watershed Tussock Tundra_US-ICt_tower...\n",
      "Processing site: Imnavait Creek Watershed Heath Tundra_US-ICh_tower...\n",
      "Processing site: Imnavait Creek Watershed Wet Sedge Tundra_US-ICs_tower...\n",
      "Processing site: Quebec - 1975 Harvested Black Spruce_CA-Qc2_tower...\n",
      "Processing site: Eight Mile Lake_US-EML_tower...\n",
      "Processing site: Anaktuvuk River Moderate Burn_US-An2_tower...\n",
      "Processing site: Anaktuvuk River Severe Burn_US-An1_tower...\n",
      "Processing site: Anaktuvuk River Unburned_US-An3_tower...\n",
      "Processing site: Lac Le Caron peatland, an ombrotrophic bog_CA-LLC_tower...\n",
      "Processing site: Nuuk Fen_GL-NuF_tower...\n",
      "Processing site: Rylekaerene_tower...\n",
      "Processing site: Seida_RU-Vrk_tower...\n",
      "Processing site: Zackenberg Fen_GL-ZaF_tower...\n",
      "Processing site: Andoya_NO-And_tower...\n",
      "Processing site: Bayelva, Spitsbergen_SJ-Blv_tower...\n",
      "Processing site: Iqaluit_CA-Iqa_tower...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/sklearn/metrics/_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing site: Pond Inlet_CA-Pin_tower...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/sklearn/metrics/_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing site: Poker Flat Research Range: Succession from fire scar to deciduous forest_US-Rpf_tower...\n",
      "Processing site: Lake Hazen, Ellesmere Island_CA-LHazen1-semidesert_tower...\n",
      "Processing site: Samoylov Island_RU-Sam (open)_tower...\n",
      "Processing site: Lettosuo_FI-Let_tower...\n",
      "Processing site: Elgeeii forest station_RU-Ege_tower...\n",
      "Processing site: Siikaneva_FI-Sii_tower...\n",
      "Processing site: Udleg practice forest_MN-Udg_tower...\n",
      "Processing site: Daring Lake_CA-DL3_tower...\n",
      "Processing site: Bonanza Creek Black Spruce_US-BZS_tower...\n",
      "Processing site: Daring Lake_CA-DL4_tower...\n",
      "Processing site: Tiksi_RU-Tks_tower...\n",
      "Processing site: Samoylov Island_RU-Sam (closed)_tower...\n",
      "Processing site: Attawapiskat River Fen_CA-ARF_tower...\n",
      "Processing site: Bonanza Creek Thermokarst Bog_US-BZB_tower...\n",
      "Processing site: Poker Flat Research Range Black Spruce Forest_US-Prr_tower...\n",
      "Processing site: Attawapiskat River Bog_CA-ARB_tower...\n",
      "Processing site: Bonanza Creek Rich Fen_US-BZF_tower...\n",
      "Processing site: Cascaden Ridge Fire Scar_US-Fcr_tower...\n",
      "Processing site: Siikaneva2_FI-Si2_tower...\n",
      "Processing site: Varrio_FI-Var_tower...\n",
      "Processing site: Adventdalen_SJ-Adv_tower...\n",
      "Processing site: Lake Hazen, Ellesmere Island_CA-LHazen2-meadow wetland_tower...\n",
      "Processing site: Tervalamminsuo_Dry_tower...\n",
      "Processing site: Tervalamminsuo_Wet_tower...\n",
      "Processing site: Barrow-BEO_US-Beo_tower...\n",
      "Processing site: Havikpak Creek_CA-HPC_tower...\n",
      "Processing site: Scotty Creek Landscape_CA-SCC_tower...\n",
      "Processing site: Barrow-BES_US-Bes_tower...\n",
      "Processing site: Trail Valley Creek_CA-TVC_tower...\n",
      "Processing site: Cherskii reference_RU-Ch2_tower...\n",
      "Processing site: NGEE Arctic Barrow_US-NGB_tower...\n",
      "Processing site: Svartberget_SE-Svb_tower...\n",
      "Processing site: Scotty Creek Bog_CA-SCB_tower...\n",
      "Processing site: Stordalen Palsa Bog_SE-Sto_tower...\n",
      "Processing site: Council, Alaska_US-KOC_tower...\n",
      "Processing site: Rosinedal-3_SE-Ros_tower...\n",
      "Processing site: Hustai grassland_MN-Hst_tower...\n",
      "Processing site: Nalaikh grassland_MN-Nkh_tower...\n",
      "Processing site: Bibai bog_JP-Bby_tower...\n",
      "Processing site: Fyodorovskoye2_RU-Fy2_tower...\n",
      "Processing site: Wolf_creek_Buckbrush_CA-WCBB_tower...\n",
      "Processing site: Wolf_creek_SparseShrub_CA-WCPLT_tower...\n",
      "Processing site: Wolf_creek_forest_CA-WCF_tower...\n",
      "Processing site: Smith Creek_CA-SMC_tower...\n",
      "Processing site: NGEE Arctic Council_US-NGC_tower...\n",
      "Processing site: Bonanza Creek Old Thermokarst Bog_US-BZo_tower...\n",
      "Processing site: Kenttarova_FI-Ken_tower...\n",
      "Processing site: NEON Healy (HEAL)_US-xHE_tower...\n",
      "Processing site: Bouleau peatland_CA-BOU_tower...\n",
      "Processing site: Bernard spruce-moss valley_tower...\n",
      "Processing site: NEON Delta Junction (DEJU)_US-xDJ_tower...\n",
      "Processing site: NEON Caribou Creek - Poker Flats Watershed (BONA)_US-xBN_tower...\n",
      "Processing site: NEON Barrow Environmental Observatory (BARR)_US-xBA_tower...\n",
      "Processing site: YKD (unburned)_US-YK2_tower...\n",
      "Processing site: Ljusdal_HY_HY_tower...\n",
      "Processing site: YKD (burned)_US-YK1_tower...\n",
      "Processing site: Ranskalankorpi_FI-Ran forestry treatment_tower...\n",
      "Processing site: Ranskalankorpi_FI-Ran_tower...\n",
      "Processing site: Stortjarn_SE-Srj_tower...\n",
      "Processing site: Wolf_creek_upper_forest_CA-WCUF_tower...\n",
      "Processing site: Halmyran_SE-Hmr_tower...\n",
      "Processing site: Halsingfors mire_SE-HfM_tower...\n",
      "Processing site: Tombstone_slavin_CA-TWOSL_tower...\n",
      "Processing site: Disko_GL-Dsk_tower...\n",
      "Processing site: Ljusdal_SLM_SLM_tower...\n",
      "Processing site: Lily Lake Fen_US-KPL_tower...\n",
      "Processing site: Abisko Stordalen birch forest_tower...\n",
      "Processing site: North Star Yedoma_US-NSY_tower...\n",
      "Processing site: Mukhrino field station, Khanty-Mansiysk, Russia_RU-Muh_tower...\n",
      "Processing site: Plotnikovo field station, Tomsk, Rusia_RU-Plt_tower...\n",
      "Processing site: Cambridge Bay - Mesic_CB-mesic_tower...\n",
      "Processing site: Igarka_RU-Iga_tower...\n",
      "Processing site: Iqaluit Tundra_CA-IQ1_tower...\n",
      "Processing site: Churchill Fen 3_CA-CF3_tower...\n",
      "Processing site: Pitsalu_tower...\n",
      "Processing site: Mittimatalik (Pond Inlet) Tundra_CA-Mtk_tower...\n",
      "Processing site: Happy Valley Wet Sedge Tundra_US-HVs_tower...\n",
      "Processing site: Happy Valley_US-HVa_tower...\n",
      "Processing site: Sag River_US-Sag_tower...\n",
      "\n",
      "Results saved to: /explore/nobackup/people/spotter5/anna_v/v2/loocv/reco/catboost_results_reco_cat.csv\n",
      "Predictions saved to: /explore/nobackup/people/spotter5/anna_v/v2/loocv/reco/catboost_predictions_reco_cat.csv\n",
      "\n",
      "--- Site-Specific Results ---\n",
      "                                                  Site       RMSE        MAE  \\\n",
      "0                           Fyodorovskoye_RU-Fyo_tower  69.524058  46.880004   \n",
      "1    Saskatchewan - Western Boreal, Mature Aspen_CA...  36.347934  23.360059   \n",
      "2    Saskatchewan - Western Boreal, Mature Jack Pin...  19.709691  14.245813   \n",
      "3                                Hyytiala_FI-Hyy_tower  24.643850  19.131102   \n",
      "4    Manitoba - Northern Old Black Spruce (former B...  39.921932  25.983450   \n",
      "..                                                 ...        ...        ...   \n",
      "148                                      Pitsalu_tower  42.983467  34.427687   \n",
      "149      Mittimatalik (Pond Inlet) Tundra_CA-Mtk_tower   6.862663   6.482311   \n",
      "150         Happy Valley Wet Sedge Tundra_US-HVs_tower  42.650290  42.025482   \n",
      "151                          Happy Valley_US-HVa_tower  46.156818  46.026550   \n",
      "152                             Sag River_US-Sag_tower  39.931313  38.972953   \n",
      "\n",
      "            R2  \n",
      "0     0.603114  \n",
      "1     0.765873  \n",
      "2     0.851730  \n",
      "3     0.838268  \n",
      "4     0.533505  \n",
      "..         ...  \n",
      "148  -1.120058  \n",
      "149  -1.378782  \n",
      "150 -30.076940  \n",
      "151 -99.305120  \n",
      "152 -47.058376  \n",
      "\n",
      "[153 rows x 4 columns]\n",
      "\n",
      "--- Pooled Metrics ---\n",
      "Pooled RMSE: 31.7239\n",
      "Pooled MAE:  19.7693\n",
      "Pooled R²:   0.6977\n",
      "\n",
      "--- Median Metrics Across Sites ---\n",
      "Median RMSE: 21.7661\n",
      "Median MAE:  15.9475\n",
      "Median R²:   0.5217\n",
      "\n",
      "Generating and saving individual site plots...\n",
      "All site plots saved to: /explore/nobackup/people/spotter5/anna_v/v2/loocv/reco/figures\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Suppress warnings\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore::FutureWarning'\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# 1. Load your dataset\n",
    "file_path = \"/explore/nobackup/people/spotter5/anna_v/v2/v2_model_training_final.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df = df[df['flux_method'] == 'EC']\n",
    "\n",
    "# 2. Create tmean_C and date\n",
    "df['tmean_C'] = df[['tmmn', 'tmmx']].mean(axis=1)\n",
    "df['date'] = pd.to_datetime(df[['year', 'month']].assign(day=1))\n",
    "\n",
    "# 3. Define predictors and target\n",
    "# Added 'land_cover' and 'month' to the list of predictors for CatBoost\n",
    "feature_cols = [\n",
    "    'EVI', 'NDVI', 'sur_refl_b01', 'sur_refl_b02', 'sur_refl_b03', \n",
    "    'sur_refl_b07', 'NDWI', 'pdsi', 'srad', 'tmean_C', 'vap', 'vs',\n",
    "    'bdod_0_100cm', 'cec_0_100cm', 'cfvo_0_100cm', 'clay_0_100cm',\n",
    "    'nitrogen_0_100cm', 'ocd_0_100cm', 'phh2o_0_100cm', 'sand_0_100cm',\n",
    "    'silt_0_100cm', 'soc_0_100cm', 'co2_cont', 'ALT',\n",
    "    'land_cover', 'month', \n",
    "    'lai', 'fpar', 'Percent_NonTree_Vegetation',\n",
    "    'Percent_NonVegetated', 'Percent_Tree_Cover'\n",
    "]\n",
    "\n",
    "target_col = 'reco'\n",
    "categorical_features = ['land_cover', 'month']\n",
    "\n",
    "# Drop rows only if the target variable or site_reference is missing.\n",
    "# CatBoost will handle missing values in the numerical predictor variables.\n",
    "df = df.dropna(subset=['site_reference', target_col])\n",
    "\n",
    "# Define output path for CSVs and create it\n",
    "out_path = os.path.join(\"/explore/nobackup/people/spotter5/anna_v/v2/loocv\", target_col)\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "# Define a separate output path for figures and create it\n",
    "figures_path = os.path.join(out_path, \"figures\")\n",
    "os.makedirs(figures_path, exist_ok=True)\n",
    "\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "# No one-hot encoding is needed for CatBoost\n",
    "X = df[feature_cols]\n",
    "y = df[target_col]\n",
    "sites = df[\"site_reference\"].unique()\n",
    "\n",
    "# Convert categorical features to 'category' dtype for CatBoost\n",
    "for col in categorical_features:\n",
    "    X[col] = X[col].astype('category')\n",
    "\n",
    "results = []\n",
    "all_preds_df_list = []\n",
    "\n",
    "# Leave-One-Site-Out CV\n",
    "for test_site in sites:\n",
    "    print(f\"Processing site: {test_site}...\")\n",
    "    train_idx = df[\"site_reference\"] != test_site\n",
    "    test_idx = df[\"site_reference\"] == test_site\n",
    "\n",
    "    if test_idx.sum() < 1:\n",
    "        continue\n",
    "\n",
    "    X_train, y_train = X.loc[train_idx], y.loc[train_idx]\n",
    "    X_test, y_test = X.loc[test_idx], y.loc[test_idx]\n",
    "    dates_test = df.loc[test_idx, \"date\"]\n",
    "\n",
    "    # Initialize and train the CatBoost model\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=700,\n",
    "        learning_rate=0.01,\n",
    "        depth=8,\n",
    "        subsample=0.7,\n",
    "        random_state=42,\n",
    "        cat_features=categorical_features,\n",
    "        verbose=0, # Suppress verbose output\n",
    "        allow_writing_files=False\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    site_df = pd.DataFrame({\n",
    "        \"Site\": test_site,\n",
    "        \"Date\": dates_test.values,\n",
    "        \"Observed\": y_test.values,\n",
    "        \"Predicted\": y_pred\n",
    "    })\n",
    "    all_preds_df_list.append(site_df)\n",
    "\n",
    "    # Metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    results.append({\n",
    "        \"Site\": test_site,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"R2\": r2\n",
    "    })\n",
    "\n",
    "# Combine results\n",
    "results_df = pd.DataFrame(results)\n",
    "all_preds_df = pd.concat(all_preds_df_list, ignore_index=True)\n",
    "\n",
    "# Save to disk with '_cat' suffix\n",
    "results_csv_path = os.path.join(out_path, f'catboost_results_{target_col}_cat.csv')\n",
    "predictions_csv_path = os.path.join(out_path, f'catboost_predictions_{target_col}_cat.csv')\n",
    "results_df.to_csv(results_csv_path, index=False)\n",
    "all_preds_df.to_csv(predictions_csv_path, index=False)\n",
    "print(f\"\\nResults saved to: {results_csv_path}\")\n",
    "print(f\"Predictions saved to: {predictions_csv_path}\")\n",
    "\n",
    "\n",
    "# Pooled metrics\n",
    "rmse_all = np.sqrt(mean_squared_error(all_preds_df[\"Observed\"], all_preds_df[\"Predicted\"]))\n",
    "r2_all = r2_score(all_preds_df[\"Observed\"], all_preds_df[\"Predicted\"])\n",
    "mae_all = mean_absolute_error(all_preds_df[\"Observed\"], all_preds_df[\"Predicted\"])\n",
    "\n",
    "print(\"\\n--- Site-Specific Results ---\")\n",
    "print(results_df)\n",
    "print(\"\\n--- Pooled Metrics ---\")\n",
    "print(f\"Pooled RMSE: {rmse_all:.4f}\")\n",
    "print(f\"Pooled MAE:  {mae_all:.4f}\")\n",
    "print(f\"Pooled R²:   {r2_all:.4f}\")\n",
    "\n",
    "# Median metrics across sites\n",
    "median_rmse = results_df[\"RMSE\"].median()\n",
    "median_mae = results_df[\"MAE\"].median()\n",
    "median_r2 = results_df[\"R2\"].median()\n",
    "\n",
    "print(\"\\n--- Median Metrics Across Sites ---\")\n",
    "print(f\"Median RMSE: {median_rmse:.4f}\")\n",
    "print(f\"Median MAE:  {median_mae:.4f}\")\n",
    "print(f\"Median R²:   {median_r2:.4f}\")\n",
    "\n",
    "# --- Plotting ---\n",
    "# Loop through each site and save a separate plot\n",
    "unique_sites = all_preds_df[\"Site\"].unique()\n",
    "if not unique_sites.any():\n",
    "    print(\"\\nNo sites to plot.\")\n",
    "else:\n",
    "    print(\"\\nGenerating and saving individual site plots...\")\n",
    "    for site in unique_sites:\n",
    "        fig, ax = plt.subplots(figsize=(12, 7))\n",
    "        \n",
    "        site_df = all_preds_df[all_preds_df[\"Site\"] == site].sort_values(\"Date\")\n",
    "        site_metrics = results_df[results_df[\"Site\"] == site].iloc[0]\n",
    "        rmse_val = round(site_metrics[\"RMSE\"], 2)\n",
    "        r2_val = round(site_metrics[\"R2\"], 2)\n",
    "        mae_val = round(site_metrics[\"MAE\"], 2)\n",
    "\n",
    "        ax.plot(site_df[\"Date\"], site_df[\"Observed\"], label=\"Observed\", marker=\"o\", linestyle='-', markersize=4)\n",
    "        ax.plot(site_df[\"Date\"], site_df[\"Predicted\"], label=\"Predicted\", marker=\"x\", linestyle='--', markersize=4)\n",
    "        ax.set_title(f\"Observed vs. Predicted {target_col} for Site: {site}\")\n",
    "        ax.set_xlabel(\"Date\")\n",
    "        ax.set_ylabel(target_col)\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "        fig.autofmt_xdate() # Auto-formats the x-axis labels for dates\n",
    "\n",
    "        # Add metrics text to the plot\n",
    "        textstr = f\"RMSE: {rmse_val}\\nMAE: {mae_val}\\nR²: {r2_val}\"\n",
    "        ax.text(\n",
    "            0.97, 0.03, textstr,\n",
    "            transform=ax.transAxes,\n",
    "            fontsize=10,\n",
    "            verticalalignment='bottom',\n",
    "            horizontalalignment='right',\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.7)\n",
    "        )\n",
    "        \n",
    "        # Define the output path for the plot\n",
    "        plot_filename = f'catboost_{target_col}_{site}_timeseries_cat.png'\n",
    "        plot_path = os.path.join(figures_path, plot_filename)\n",
    "        \n",
    "        # Save the figure\n",
    "        plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        # Close the plot to free up memory\n",
    "        plt.close(fig)\n",
    "        \n",
    "    print(f\"All site plots saved to: {figures_path}\")\n",
    "\n",
    "\n",
    "out_path = '/explore/nobackup/people/spotter5/anna_v/v2/models'\n",
    "os.makedirs(out_path, exist_ok = True)\n",
    "model_filename = f'{target_col}.json'\n",
    "model.save_model(os.path.join(out_path, model_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd7a688-60c4-4814-b6e3-3152ac02f8a9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "LOSO CH4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd6c411-274b-45c6-a0ff-d8ef2b746396",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Suppress warnings\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore::FutureWarning'\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# 1. Load your dataset\n",
    "file_path = \"/explore/nobackup/people/spotter5/anna_v/v2/v2_model_training_final.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df = df[df['flux_method'] == 'EC']\n",
    "\n",
    "# 2. Create tmean_C and date\n",
    "df['tmean_C'] = df[['tmmn', 'tmmx']].mean(axis=1)\n",
    "df['date'] = pd.to_datetime(df[['year', 'month']].assign(day=1))\n",
    "\n",
    "# 3. Define predictors and target\n",
    "# Added 'land_cover' and 'month' to the list of predictors for CatBoost\n",
    "feature_cols = [\n",
    "    'EVI', 'NDVI', 'sur_refl_b01', 'sur_refl_b02', 'sur_refl_b03', \n",
    "    'sur_refl_b07', 'NDWI', 'pdsi', 'srad', 'tmean_C', 'vap', 'vs',\n",
    "    'bdod_0_100cm', 'cec_0_100cm', 'cfvo_0_100cm', 'clay_0_100cm',\n",
    "    'nitrogen_0_100cm', 'ocd_0_100cm', 'phh2o_0_100cm', 'sand_0_100cm',\n",
    "    'silt_0_100cm', 'soc_0_100cm', 'co2_cont', 'ALT',\n",
    "    'land_cover', 'month', \n",
    "    'lai', 'fpar', 'Percent_NonTree_Vegetation',\n",
    "    'Percent_NonVegetated', 'Percent_Tree_Cover'\n",
    "]\n",
    "target_col = 'ch4_flux_total'\n",
    "categorical_features = ['land_cover', 'month']\n",
    "\n",
    "# Drop rows only if the target variable or site_reference is missing.\n",
    "# CatBoost will handle missing values in the numerical predictor variables.\n",
    "df = df.dropna(subset=['site_reference', target_col])\n",
    "\n",
    "# Define output path for CSVs and create it\n",
    "out_path = os.path.join(\"/explore/nobackup/people/spotter5/anna_v/v2/loocv\", target_col)\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "# Define a separate output path for figures and create it\n",
    "figures_path = os.path.join(out_path, \"figures\")\n",
    "os.makedirs(figures_path, exist_ok=True)\n",
    "\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "# No one-hot encoding is needed for CatBoost\n",
    "X = df[feature_cols]\n",
    "y = df[target_col]\n",
    "sites = df[\"site_reference\"].unique()\n",
    "\n",
    "# Convert categorical features to 'category' dtype for CatBoost\n",
    "for col in categorical_features:\n",
    "    X[col] = X[col].astype('category')\n",
    "\n",
    "results = []\n",
    "all_preds_df_list = []\n",
    "\n",
    "# Leave-One-Site-Out CV\n",
    "for test_site in sites:\n",
    "    print(f\"Processing site: {test_site}...\")\n",
    "    train_idx = df[\"site_reference\"] != test_site\n",
    "    test_idx = df[\"site_reference\"] == test_site\n",
    "\n",
    "    if test_idx.sum() < 1:\n",
    "        continue\n",
    "\n",
    "    X_train, y_train = X.loc[train_idx], y.loc[train_idx]\n",
    "    X_test, y_test = X.loc[test_idx], y.loc[test_idx]\n",
    "    dates_test = df.loc[test_idx, \"date\"]\n",
    "\n",
    "    # Initialize and train the CatBoost model\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=700,\n",
    "        learning_rate=0.01,\n",
    "        depth=8,\n",
    "        subsample=0.7,\n",
    "        random_state=42,\n",
    "        cat_features=categorical_features,\n",
    "        verbose=0, # Suppress verbose output\n",
    "        allow_writing_files=False\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    site_df = pd.DataFrame({\n",
    "        \"Site\": test_site,\n",
    "        \"Date\": dates_test.values,\n",
    "        \"Observed\": y_test.values,\n",
    "        \"Predicted\": y_pred\n",
    "    })\n",
    "    all_preds_df_list.append(site_df)\n",
    "\n",
    "    # Metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    results.append({\n",
    "        \"Site\": test_site,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"R2\": r2\n",
    "    })\n",
    "\n",
    "# Combine results\n",
    "results_df = pd.DataFrame(results)\n",
    "all_preds_df = pd.concat(all_preds_df_list, ignore_index=True)\n",
    "\n",
    "# Save to disk with '_cat' suffix\n",
    "results_csv_path = os.path.join(out_path, f'catboost_results_{target_col}_cat.csv')\n",
    "predictions_csv_path = os.path.join(out_path, f'catboost_predictions_{target_col}_cat.csv')\n",
    "results_df.to_csv(results_csv_path, index=False)\n",
    "all_preds_df.to_csv(predictions_csv_path, index=False)\n",
    "print(f\"\\nResults saved to: {results_csv_path}\")\n",
    "print(f\"Predictions saved to: {predictions_csv_path}\")\n",
    "\n",
    "\n",
    "# Pooled metrics\n",
    "rmse_all = np.sqrt(mean_squared_error(all_preds_df[\"Observed\"], all_preds_df[\"Predicted\"]))\n",
    "r2_all = r2_score(all_preds_df[\"Observed\"], all_preds_df[\"Predicted\"])\n",
    "mae_all = mean_absolute_error(all_preds_df[\"Observed\"], all_preds_df[\"Predicted\"])\n",
    "\n",
    "print(\"\\n--- Site-Specific Results ---\")\n",
    "print(results_df)\n",
    "print(\"\\n--- Pooled Metrics ---\")\n",
    "print(f\"Pooled RMSE: {rmse_all:.4f}\")\n",
    "print(f\"Pooled MAE:  {mae_all:.4f}\")\n",
    "print(f\"Pooled R²:   {r2_all:.4f}\")\n",
    "\n",
    "# Median metrics across sites\n",
    "median_rmse = results_df[\"RMSE\"].median()\n",
    "median_mae = results_df[\"MAE\"].median()\n",
    "median_r2 = results_df[\"R2\"].median()\n",
    "\n",
    "print(\"\\n--- Median Metrics Across Sites ---\")\n",
    "print(f\"Median RMSE: {median_rmse:.4f}\")\n",
    "print(f\"Median MAE:  {median_mae:.4f}\")\n",
    "print(f\"Median R²:   {median_r2:.4f}\")\n",
    "\n",
    "# --- Plotting ---\n",
    "# Loop through each site and save a separate plot\n",
    "unique_sites = all_preds_df[\"Site\"].unique()\n",
    "if not unique_sites.any():\n",
    "    print(\"\\nNo sites to plot.\")\n",
    "else:\n",
    "    print(\"\\nGenerating and saving individual site plots...\")\n",
    "    for site in unique_sites:\n",
    "        fig, ax = plt.subplots(figsize=(12, 7))\n",
    "        \n",
    "        site_df = all_preds_df[all_preds_df[\"Site\"] == site].sort_values(\"Date\")\n",
    "        site_metrics = results_df[results_df[\"Site\"] == site].iloc[0]\n",
    "        rmse_val = round(site_metrics[\"RMSE\"], 2)\n",
    "        r2_val = round(site_metrics[\"R2\"], 2)\n",
    "        mae_val = round(site_metrics[\"MAE\"], 2)\n",
    "\n",
    "        ax.plot(site_df[\"Date\"], site_df[\"Observed\"], label=\"Observed\", marker=\"o\", linestyle='-', markersize=4)\n",
    "        ax.plot(site_df[\"Date\"], site_df[\"Predicted\"], label=\"Predicted\", marker=\"x\", linestyle='--', markersize=4)\n",
    "        ax.set_title(f\"Observed vs. Predicted {target_col} for Site: {site}\")\n",
    "        ax.set_xlabel(\"Date\")\n",
    "        ax.set_ylabel(target_col)\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "        fig.autofmt_xdate() # Auto-formats the x-axis labels for dates\n",
    "\n",
    "        # Add metrics text to the plot\n",
    "        textstr = f\"RMSE: {rmse_val}\\nMAE: {mae_val}\\nR²: {r2_val}\"\n",
    "        ax.text(\n",
    "            0.97, 0.03, textstr,\n",
    "            transform=ax.transAxes,\n",
    "            fontsize=10,\n",
    "            verticalalignment='bottom',\n",
    "            horizontalalignment='right',\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.7)\n",
    "        )\n",
    "        \n",
    "        # Define the output path for the plot\n",
    "        plot_filename = f'catboost_{target_col}_{site}_timeseries_cat.png'\n",
    "        plot_path = os.path.join(figures_path, plot_filename)\n",
    "        \n",
    "        # Save the figure\n",
    "        plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        # Close the plot to free up memory\n",
    "        plt.close(fig)\n",
    "        \n",
    "    print(f\"All site plots saved to: {figures_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fb0478-16b9-45a2-9f72-06d4f7041ed7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "'t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa0a3462-e2e4-48c6-9dbe-3abd4247d566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    17182\n",
       "3    16239\n",
       "0    15710\n",
       "1     4588\n",
       "2     2412\n",
       "Name: land_cover, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = \"/explore/nobackup/people/spotter5/anna_v/v2/v2_model_training_final.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df = df[df['land_cover'] != -9999]\n",
    "\n",
    "df['land_cover'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f8c7d95-10a8-4a57-96a8-ae6579df36ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbe1c55-289c-4495-b085-1462bd9b3bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-xgboost_gpu]",
   "language": "python",
   "name": "conda-env-.conda-xgboost_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
